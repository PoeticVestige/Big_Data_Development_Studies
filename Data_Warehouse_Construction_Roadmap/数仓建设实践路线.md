见B站语兴数仓建设实践路线，结合着人力数仓讲

具体参考./数仓建设实践路线.xmind

# 人力数仓项目

0-1如何搭建数仓的步骤可以见数仓建设学习路线

## 认识业务&规划架构

技术选型：选lambda架构（除此之外还有hsap、流批一体）。考虑到人力资源业务数据量较小，实时场景可能占整体10%-15%，盲目去追流批一体架构会造成资源浪费情况，因此选择lambda作为讲解。（0-1如何搭建数仓第一步）

架构定下来后，选技术栈，基本已经完成了。新人只需要弄懂：**数据源有哪些、调度工具、离线数据传输（Spark SQL）、实时数据传输（Flink CDC）、离线计算引擎（Spark3）、实时计算引擎（Flink14）、olap（落地，用doris）。这样定好的技术，要开始刨析业务。**（0-1如何搭建数仓第一步）

（0-1如何搭建数仓第二步：定数据规范）

（（0-1如何搭建数仓第三步：构建大图））

架构图（图1）

<img src=".\image\数仓建设实践路线_人力数仓架构图.png" style="zoom:50%;" />

版图（图2）：略

- 数据应用
- 数据服务
- 数据资产
- 数据基建

对业务的理解图（图3）：业务及主题域划分：（给一个业务，数仓0-1如何搭建？根据业务流程。数据域划分一般有两种方式：一种是根据业务划分（根据业务划分时，不是一个流程一个数据域，可能一系列业务流程对应一个数据域）、一种是根据系统模块划分，从操作的角度出发。主题域是根据业务的分析需求划分。从分析的角度出发）

sop（业务流程）包括员工从招聘到入职在职离职整体生命周期，同时也包含集团内部运营、行政管理

- 人才招聘
  - 招聘岗位发布
  - 招聘渠道
  - 简历
  - 应聘
  - 面试
  - 招聘体验
  - 体检
  - offer
  - 背调
- 员工管理
  - 入职
  - 试用期
  - 绩效
  - 晋升
  - 考勤
  - 调动
  - 学习发展
  - 离职

- 组织发展
  - 组织架构
  - 干部考量
  - 敬业度/满意度

- 运营管理
  - 行政
  - ssc（共享服务中心是通过对人员、技术和流程的有效整合，实现组织内公共流程的标准化和精简化的一种创新手段）
  - 内部社区运营

- 数据管理
  - 元数据
  - 数据质量
  - 工单
  - 指标系统
  - 数据治理




里面要注意数据管理：元数据就是描述数据的数据。数据质量（DQC,看数据变化，垃圾数据监控等、捞出一些自己想捞出来的数据）

然后后面可以开始接数据了。数据集成

## 数仓标准

### 业务主题域命名规范

数据域：

- 人才招聘（rec，一级数据域）
- 员工管理（em，一级数据域）
- 组织发展（org，一级数据域）
- 运营管理（om，一级数据域）
- 数据管理（dm，一级数据域）

### 数仓分层规范

- ODS（接入层）：全称Operational Data Store，ODS层是最接近数据源的一层，从数据源（api、数据库等）将数据同步数仓中，中间不做任何处理操作
- DIM（维度）：全称Dimension，用于存放维度数据，在DWD或者DWM层做维度退化
- DWD（明细层）:全称Data Warehouse Detail，是数仓明细数据层，对ODS层的数据进行关联，清洗，维度退化（将维度表中维度数据放入明细表中），转换，主题域建设等操作
- DWS（汇总层）：全称Data WareHouse Service，按照主题域、颗粒度（例如员工、部门）划分，按照周期粒度、维度聚合形成指标较多的宽表，用于提供后续的业务查询，数据应用，最重要一点需要在DWS层完成指标口径统一及沉淀
- ADS（应用层）：全称Applacation data service，按照应用域，颗粒度划分（例如员工、部门）划分，按照应用主题将对应数据标签补充至应用层，最终形成用户画像及专项应用

### 元数据规范

#### 表命名

- ODS层（接入层）
  - 全量：ods__{业务数据库名}_{业务数据表名}
  - 增量：ods__{业务数据库名}_{业务数据表名}_delta
- DWD层（明细层）：dwd\_{一级数据域}\_{二级数据域}\_{三级数据域}\_{业务过程（不清楚或没有写detail）}_存储策略（df/di，df为全量数据，di为增量数据)）
- DWM（轻度汇总层）：dwd\_{一级数据域}\_{业务过程（不清楚或没有写detail）}_存储策略（df/di，df为全量数据，di为增量数据)）
- DWS（汇总层）：dws_{一级数据域}_{二级数据域}_{三级数据域}_{颗粒度}（例如员工/部门）_{业务过程}_{周期粒度}（例如近30天写30d、90天写3m）
- ADS（应用层）：ads_{应用主题/应用场景}_{颗粒度}（例如买家/卖家）_{业务过程}_{调度周期}（例如1天调度一次写1d）
- DIM（维度）：dim__{维度定义}（例如日期写date）
- tmp表（临时表）：tmp_{表名}_{临时表编号}
- view（视图）：{表名}_view
- 备份表：{表名}_bak
- 表名元素
  - 存储策略
    - df：（日全量）
    - di
    - df
    - di
    - mf：（月全量）
    - mi
    - wf：（周全量）
    - wi
    - i：increment，f：full
  - 颗粒度
    - apply
    - dept
    - emp
    - interviewer：面试官
  - 统计周期
    - 1d
    - 1m
    - 1y
    - 3m
    - 6m
    - nd
    - td
  - 调度周期
    - 1d
    - 1m
    - h

#### 字段命名

- 是否xxxxx用户，类型字段命名规范：is_{内容}
- 枚举值类型字段命名规范：xxxx_type
- 时间戳类型字段命名规范：xxx_date,xxx_time
- 周期指标命名：{内容}\_{时间描述}（如最近一次last1，最近两次last2，历史his，最近第二次last2nd)_date、最近180天 6m
- 百分比命名：{内容}_rate
- 数值类型（整型）命名：{内容}\_cnt\_{周期}（周期看情况加）
- 数值类型（小数）金额命名：{内容}\_amt_{周期}（周期看情况加）
- 两个时间段之间统计命名：xxx（时间段1内行为）\_xxx（时间段2内操作）\_dur

#### 字段类型

- 文本：string
- 日期：string
- 整数：bigint
- 小数
  - 高精度用decimal
  - 正常使用double
- 枚举值
  - 单枚举-'Y'/'N'-string
  - 多枚举-string
- 各类id：string

#### 数据模型标注规范

- owner
- 表中文名+使用说明
- 每个开发字段中文名（中文名需要包含该字段内容，例如是否为xxxx用户，需要写出包含内容(Y/N)）
- 每个模型的颗粒度
- 每个模型的主键（联合主键）

#### 任务命名

- 传输任务
  - 数据源 生产端2消费端_库名_表名：mysql2hive_ods_xx_xxx
  - hive ：生产端2消费端_表名：hive2doris_xx
- 开发任务
  - 任务名与表名一致
  - 子模块且为sql模块
    - 转换处理：trans_表名
    - 备份：bak_表名
    - 开发：sql_表名
  - 子模块为java/python：java/python\_{操作内容}_{表名}

#### 模型分区生命周期

ODS：365天-1年

DWD：1095天-3年 

DWS：1095天-3年（部分可到5年） 

ADS：1825天-5年 

DIM：1095天-3年

#### 模型分区

建议最多二级分区，超了2级分区会造成数据长周期存储问题，1级分区为业务日期，2级根据业务场景设置

#### 参数命名

lst1date（t-1）

lst2date（t-2）

### 模型建设规范

-  遵循原则
  - 高内聚低耦合、公共逻辑下沉、规范一致性、可扩展性，成本与性能平衡
  - 识别业务过程->选择事实表类型->声明颗粒度及维度->补充数据域下度量值->维度退化
- 模型建设五要素
  - 数据域：对当前业务场景或业务sop进行拆分完成对应数据建设
  - 事实表设计：围绕着业务过程来设计，通过获取描述业务过程的度量来表达业务过程，包含了引用的维度和与业务过程有关的度量。
  - 维度：对当前场景描述及补充
  - 颗粒度：主题域下场景用户再进行细致拆分（例如用户可拆分为买家或卖家），颗粒度必须拆分为不可拆分的状态（例如用户拆分为买家，买家不可拆分）
  - 度量值：对场景下数值类型的数据记录
- 模型建设工具

### 流程制定

- 日常开发整体流程
  <img src=".\image\模型建设过程.png" style="zoom:50%;" />

- 上线/变更规范

  - 模型上线/变更流程

    - 模型上线：设计模型-->组内模型评审-->代码编写-->提交运行(dev环境)-->代码审核数据校验(数据校验时需要给审核人提供数据比对结果)-->配置DQC-->数据初始化(线上环境)

    - 模型变更（例如加字段）：确定需求(了解需求背景)-->代码编写-->提交运行(dev环境)-->代码审核&数据校验(数据校验时需要给审核人提供数据比对结果)-->配置DQC（可省略，或添加业务dqc）-->数据初始化(线上环境)

    - 模型评审：

      ```txt 
      dwd
      - 1：设计是否满足5要素（颗粒度（买家 or 卖家这种）清晰、主题域有划分、维度属性退化到模型、度量值是否合理（dwd存明细不做聚合操作）、全量增量是否有做区分） 
      - 2：内容是否添加插入数据日期及时间字段、内容是否将类型转化（例如业务系统传入1 2 3  数仓需要case 转化）、脱敏字段是否处理（看业务场景不一定要做） 
      - 3：表/字段命名是否按照规范来命名、字段属性是否按照规范、字段comment是否清晰（要精确到内容 例如xxx_date comment xxx日期类型（yyyy-mm-dd）） 
      - 4：任务owner是否标清楚、模型对应业务过程是否描述清楚、颗粒度是否有描述、表使用说明是否添加（可不写）、表生命周期/存储格式（建议parquet）是否按照标准、核心表是否有重点标注 
      dws 
      - 1：颗粒度（买家 or 卖家这种）清晰、主题域有划分、指标口径是否存在复用，表快照周期是否一致（例如存1m指标里面加入1y指标） 
      - 2：内容是否添加插入数据日期及时间字段、脱敏字段是否处理（看业务场景不一定要做） 
      - 3：表/字段命名是否按照规范来命名，字段属性是否按照规范，字段comment是否清晰（要精确到内容），要求高精度指标是否使用decimal类型 
      - 4：任务owner是否标清楚，模型对应业务过程是否描述清楚，颗粒度是否有描述，表使用说明是否添加（可不写），表生命周期/存储格式（建议parquet）是否按照标准，核心表是否有重点标注 
      ads 
      - 1：颗粒度（买家 or 卖家这种）清晰、应用层面和场景是否（应用层面例如：风控 场景例如：黑名单）有划分、标签及指标是否存在复用，调度周期是否描述清楚 
      - 2：内容是否添加插入数据日期及时间字段、脱敏字段是否处理（看业务场景不一定要做） 
      - 3：表/字段命名是否按照规范来命名，字段属性是否按照规范，字段comment是否清晰（要精确到内容，例如is_xxxx_user 是否xxx用户（Y/N）） 
      - 4：任务owner是否标清楚，模型对应业务过程及应用场景是否描述清楚，颗粒度是否有描述，表使用说明是否添加（可不写），表生命周期/存储格式（建议parquet）是否按照标准，核心表是否有重点标注
      ```

    - 代码检验工具

      - 数据探查:表数据量、关键性字段扫描（特指主键），唯一性、最大最小值/长度，空值占比、其余字段扫描：空值占比、最大最小值/长度、枚举值占比
      - 数据比对

    - DQC配置

  - 指标变更流程：如果发现字段变更后对下游自己的表/报表产生影响，那自己负责修改代码并让其他同学进行代码审核、数据质量审核且任务运行成功后方可发布线上    如果下游血缘存在不是自己的表/报表，需要在相关业务群里说一下/找到下游表owner/报表owner发送通知，让下游owner进行修改，如联系不上需要向owner的leader说明问题，并且让下游表/报表的owner当天回复一下受不受影响，不回复则对方承担问题责任，如果对方不接受修改方案，需要双方约定一下修改内容、修改日期，重定方案。

### 参数规范

参数并不是设置越多任务性能越好，根据数据量、消耗、运行时间进行调整达到合理效果

#### Hive

- `set hive.auto.convert.join = true; `（是否自动转化成mapjoin）
- `set hive.map.aggr=true; `（用于控制负载均衡，顶层的聚合操作放在Map阶段执行，从而减轻清洗阶段数据传输和Reduce阶段的执行时间，提升总体性能，该设置会消耗更多的内存）
- `set hive.groupby.skewindata=true;` （用于控制负载均衡，当数据出现倾斜时，如果该变量设置为true，那么Hive会自动进行负载均衡 ）
- `set hive.merge.mapfiles=true; ` （用于hive引擎合并小文件使用）
- `set mapreduce.map.memory.mb=4096;`	（设置map内存大小，解决memory占用过大/小 ）
- `set mapreduce.reduce.memory.mb=4096;`（设置reduce内存大小，解决memory占用过大/小）
- `set mapreduce.reduce.memory.mb=4096;`（设置reduce内存大小，解决memory占用过大/小）
- `set hive.exec.dynamic.partition.mode=nonstrict;`（动态分区开启）

#### Spark

- `set spark.sql.legacy.parquet.datetimeRebaseModeInRead=LEGACY;`（用于spark3中字段类型不匹配（例如datetime无法转换成date），消除sql中时间歧义，将Spark .sql. LEGACY . timeparserpolicy设置为LEGACY来恢复Spark 3.0之前的状态来转化）
- `set spark.sql.adaptive.enabled=true;`（是否开启调整partition功能，如果开启，spark.sql.shuffle.partitions设置的partition可能会被合并到一个reducer里运行。平台默认开启，同时强烈建议开启。理由：更好利用单个executor的性能，还能缓解小文件问题）
- `set spark.sql.hive.convertInsertingPartitionedTable=false;`（使用spark3引擎必填）

### 其他规范

#### 补数据规范

- 方法1：
  ```txt
  先创建temp表将数据插入temp表中，再把数据导入到线上表中（切记创建temp表时候需要加上stored as parquet格式转化以及spark3的引擎），最后通过运维中心补数据
  例如如下代码:
  
  drop table if exists xxx.tmp_table_name_01;
  create table xxx.tmp_table_name_01
  stored as parquet--必须添加
  as
  select
  t0.id
  from
  xxx.table_name t0
  where t0.ds='${lst1date}';
  
  insert overwrite table xxx.table_name partition (ds='${lst1date}')
  select
  id
  from xxx.tmp_table_name_01
  ```

- 方法2：
  ```txt
  采用动态分区数据插入（切记使用spark3的引擎）
  set hive.exec.dynamic.partition.mode=nonstrict;
  insert overwrite table xxx.table_name partition (ds)
  select
  t0.id,
  t0.ds--必须添加
  from
  xxx.table_name t0
  where t0.ds>='2023-03-01'
  and t0.ds<='2023-03-11'
  ```

#### 代码书写规范

内容过多，这里会单独出一期

#### 任务资源配置规范

- Driver-1024M,Executor-1,Executor内存-2048M
- 范围240+字段 5600w数据给 Driver=2048 Executor=16 Executor内存=8192

- 看数据量和计算复杂程度 一般 dws ads字段多且计算 且数据量千万以内 给Driver=1024Executor=2 Executor内存=2048/4096 千万到亿给Driver=2048 Executor=4/8 Executor内存=4096/8192
- 看数据量和计算复杂程度 一般 dwd 没啥计算只是join 转换且数据量千万以内 给Driver=1024Executor=1 Executor内存=2048/1024 千万到亿给Driver=2048 Executor=2/4 Executor内存=2048/4096
- 规范没有强制要求，大家需要看任务具体情况来定，如果计算多了 建议多给core 增大并发。



## 数据基建（DWD、DWS）

### 数仓初始期要完成的内容

数仓初始期 

1. 明确组织架构业务流程及内容  

2. 根据业务场景制定架构方向及技术栈选型或者买平台具体资源要根据部门预算调整  
3. 对当前业务梳理 明确数据源及数据域、主题域划分 
4. 确定一期要做的大方向 数据版图梳理okr制定 
5. 业务及主题域命名规范、数仓分层规范、元数据规范、模型建设规范、流程制定制定  
6. 确认核心指标口径，完成核心数据表接入及模型建设ods->dwd->dws  7.根据业务场景完成应用层场景数据模型建设支撑下游1期的专题报告及看板搭建

### 项目空间建设

- yx_ods
- yx_dwd
- yx_dws
- yx_ads

### 角色配置

- 数仓开发
- 数据分析
- 数据只读
- 任务运维

### 数据接入（弄ods层的数据）

#### 核心数据对应的数据源头

-mysql：说明来自MySQL

-kafka：说明来自kafka

数据传输任务，记得配DQC

##### 员工信息

基础信息库（yx_base）-mysql

##### 员工管理

- 入职系统库（yx_entrant）-mysql
- 试用期系统库（yx_probation）-mysql
- 绩效-mysql
- 盘点-mysql
- 考勤-mysql
- 晋升-mysql
- 调动-mysql
- 学习发展-kafka
- 离职-mysql

##### 招聘库

- 需求发布-mysql
- 招聘渠道-kafka
- 简历-mysql
- 面试-mysql
- 应聘-mysql
- 被调-mysql
- offer-mysql

##### 流程运营库

- 行政库-mysql
- ssc-api数据源
  - 由于是api传输进数仓，所以在选择接入数据时，要明白分多少页，每页多少数据
  - 由于是api接入，会产生大量小文件在ODS层，因此建议ODS前再加工一层解析json及将小文件通过spark3合并
- 内部社区运营-kafka数据源

##### 数据质量库

ods_dq_whitelist

#### 数据源配置

见./数仓建设实践路线.xmind

### 维表梳理及接入

使用接入的ods表，写sql，就是将ods的数据基线下面所说的操作。

写维表的意义是什么呢？做总线矩阵时用得到，每个数据域（相同的业务环节）里的流程表，放在同一个维度下去看，这样就需要将维表里的一些维度信息退化到dwd层里，（注意区别颗粒度）。做ads时作为驱动表

例如：

```sql
/**
 部门维度表 
 owner:语兴
*/
set sparksql.hive.convertInsertingPartitionedTable = false --解决spark3任务跑完后，无法同步到impala的问题
insert overwrite table yx_dim.dim_dept PARTITION(ds = '${lst1date}')
select code as dept_id--部门id 
       ,name as dept_name --部门名称
       ,cast(`level` as string) as dept_level--部门层级
       ,case when is_valid='true'
            then 'Y' 
            else 'N'
       end as is_valid--是否有效部门
       ,first_department_code as dept1_id--一级部门编码 
       ,first_department_name as dept1_name--一级部门名称 
       ,second_department_code as dept2_id--二级部门编码
       ,second_department_name as dept2_name--二级部门名称 
       ,third_department_code as dept3_id--三级部门编码 
       ,third_department_name as dept3_name--三级部门名称
       ,all_parent_department_name as all_dept_name--所有父级部门名称用-符号隔开 
       ,bg_code as bg_id --事业群
       ,bg_name--事业群名称
       ,bu_code as bu_id--事业群id
       ,bu_name--bu名称
from
yx_ods.ods_yx_base_department 
--bg09 bg10为合资公司对应业务线需要剔除 
where bg_code not in('bg09','bg10') 
and ds='${lst1date}'
```

yx_dim.dim_dept这个数据库、数据表事先已经建好了。然后参考模型上线流程：设计模型-->组内模型评审-->代码编写-->提交运行(dev环境)-->代码审核数据校验(数据校验时需要给审核人提供数据比对结果)-->配置DQC-->数据初始化(线上环境)

编写代码——>数据比对——>配置DQC——>试运行，提交工单——>审核通过——>到了线上模式（开启报警、开启调度，每天调度，选择几点跑，看看任务在不在基线上，配置依赖）——>可能需要补数据。数据比对和配置DQC可互换

#### 业务维表

- 员工维表（dim_emp）
  - 需要从ods基础信息表去关联、转换、清洗、命名更换制作
- 部门维表(dim_dept)
  - 直接抽取后清洗、转换、命名更换制作
- 岗位维表(dim_post)
  - 直接抽取后清洗、转换、命名更换制作
- 教育信息维表(dim_ university)
  - 直接抽取后清洗、转换、命名更换制作
- 晋升人员信息表(dim_promote_emp)
  - 注意点：要注意的点员工存在历史晋升情况，例如员工晋升后离职再复职，需要取最新数据
  - 用途：提升复用性后续开发中可直接取维度表中基础属性，无需再次关联，同时用于ads层作为驱动表（主表）
  - 直接抽取后清洗、转换、命名更换、取最新入职后员工数据制作

#### 公共维表

- 地区：手工上传
- 日期：手工上传



### 核心cdm层建设

#### DWD

##### 招聘域（rec）

- 招聘岗位发布（demand）
- 招聘渠道（channel）
- 简历（resume）
- 应聘（appl）
- 面试（interview）
- 招聘体验（exp）
- 背调（surv）
- offer（offer）

##### 员工管理域(em)

- 入职（entry）
  - 数据域对应业务流程：员工接offer->预计入职->体检->被调->入职->组织架构确定->合同签署->账号开通->入职体验调查
  - 数据模型：dwd_em_entry_detail_df
    - 模型建设5要素
      - 维度——部门、职位等
      - 数据表类型——周期快照事实表
      - 数据域——入职
      - 度量——竞业金额等
      - 颗粒度——员工
    - 代码操作
      - code转化为中文
      - 关联
      - 部门、职位等维度退化
    - 表依赖——根据业务流程去找要用到的ods表
- 试用期（probation）
  - 数据域对应业务流程：入职结束->试用期开始->试用期阶段->转正评审->评审结束->转正/汰换
  - 数据模型：dwd_em_probation_detail_df
    - 模型建设五要素
      - 维度——部门
      - 颗粒度——员工
      - 数据域——试用期
      - 度量——暂无
      - 数据表类型——周期快照事实表

    - 代码操作
      - code转换成中文
      - 关联
      - 部门维度退化

    - 表依赖——根据业务流程去找要用到的ods表
- 绩效（mbo）
  - 数据域对应业务流程：绩效自评提醒->绩效自评->主管绩效点评->绩效hr侧归档->绩效申诉->绩效改进pip（performance improvement plan，绩效改进计划）
  - 数据模型：dwd_em_mbo_self_assessment_detail_df
    - 模型建设五要素
    - 代码操作
    - 表依赖 

  - 数据模型：dwd_em_mbo_result_detail_df
  - 数据模型：dwd_em_mbo_appeal_detail_df
- 晋升（promote）
- 盘点（review）
- 考勤（atnd）：考勤用的di（日增量 ）:考勤ods的数据都是用t-2的数据，因为t-1的数据还没在ods里弄好，因为有些打卡下班数据会落在t里头
- 调动（adjust）
- 学习发展（train）
- 离职（resign）

##### 组织发展域（org）

见 ./数仓建设实践路线.xmind

##### 运营管理域（om）

见 ./数仓建设实践路线.xmind

##### 数据管理域（dm）

见 ./数仓建设实践路线.xmind

##### 数据质量域（dq）

见 ./数仓建设实践路线.xmind 



#### DWS

dws到底要做什么事？ 

沟通口径，每个指标要做成什么样子？

dws是按照颗粒度、维度等进行聚合产生的汇总数据模型 

（1）保障的是指标口径统一，能够为ads提供复用 

（2）对dwd的明细内容按照不同颗粒度去划分划分标准需要看下游数据分析侧需要看什么颗粒度下的数据 

（3）按照指标的周期做好周期的划分，保障每个数据模型指标周期统一 

（4）按照如上内容进行聚合计算（dws基本只放置派生指标）

注意点：大多数派生指标是数值类型的，比如bigint，int，decimal之类的，对于像“90天内最早上班时间”这类的指标，一般更像标签，在ads做

##### 员工管理域-考勤域

- 数据域对应业务流程（与dwd一致）
  - 员工考勤日上班打卡->中间打卡->下班打卡->考勤结果分析->加班
  - 请假->OA流程->请假内容分析
- 数据模型
  - dws_em_atnd_emp_target_90d
    - 模型建设五要素
      - 颗粒度：员工
      - 事实表类型:周期快照事实表（按照周期-90统计）
      - 数据域——考勤
      - 度量——>派生指标：最近90天迟到次数、最近90天平均工时（小时）、最近90天使用年假次数等
      - 维度：部门、员工类型等
    - 代码操作
      - 统一指标口径完成计算
      - 按照维度与员工颗粒度聚合
      - 通过子查询完成其他内容补充，同时提升运行效率
      - 最近90天的周期过滤数据
    - 表依赖
      - dwd_em_atnd_detail_di——员工考勤信息表
  - dws_em_atnd_target_mtd （mtd是月初截至到至今）
    - 模型建设五要素
      - 颗粒度：员工
      - 事实表类型:周期快照事实表（按周期-月初截止至今统计，例如ds=‘2023-05-19'则统计'2023-05-01'到'2023-05-19'的数据，此时4月分区'2023-04-30'存储的为'2023-04-01'到'2023-04-30‘的数据）
      - 数据域——考勤
      - 度量——>月初至今工作平均加班时长（小时）、月初至今平均工时（小时）、月初至今上午离岗次数（出园区时长超过60分钟标准）等
      - 维度：部门、员工类型等
    - 代码操作
      - 统一指标口径完成计算
      - 按照维度与员工颗粒度聚合
      - 通过子查询完成其他内容补充，同时提升运行效率
      - 按照月初截止至今的周期过滤数据
    - 表依赖
      - dwd_em_atnd_detail_di——员工考勤信息表
  - dws_em_atnd_dept_target_1d  （周期-最近1天） 但参数输入的是date-2的数据（也就是对date-2的数据进行处理），因为，date-1的数据可能在date凌晨，没更新好。

##### 晋升

## 数据应用（ADS）——做ADS一般流程

### ADS-晋升流程专题分析

#### 项目背景 

语兴集团每年都会为员工提供晋升通道，保障优质员工在专业及管理能力侧能够提升自己，从而使公司业务及员工能力有所发展，但目前缺乏晋升类数据支撑，导致晋升流程合规性以及评审情况无法得到保障，从而无法看清晋升具体情况

#### 从数分侧角度看

##### 业务流程

晋升活动开始->提名条件->员工提名->提交材料->评审（材料评审可免答辩）->评审结果（综合结果与点评）->申诉

晋升前（活动到提名）、晋升中（员工提交材料、评审、结果）、晋升后（归档，申诉）

##### 指标拆解

晋升（最终结果点）

- 提名率
- 通过率



##### 准备的看板

- 看板1.晋升数据分析整体大盘情况
- 看板2:员工提名情况
  - 部门角度
  - 员工角度
- 看板3:整体晋升流程规范情况
  - 部门角度
  - 员工角度
- 看板4:从评委角度去看员工通过情况（去看评委规范性）
  - 部门角度
  - 员工角度
- 看板5:晋升结果与晋升后
  - 部门角度
  - 员工角度



#### 从数仓侧角度看

- ods、dwd、dws内容在第三章数据基建篇下数据接入、维度表、**核心cdm层建设对应的晋升模块**
- 现状梳理（跟数仓建设学习路线里，数据资产建设很像）
  - 业务流程，业务场景
    - 员工颗粒度下晋升流程数据模型
    - 部门颗粒度下晋升指标统计模型
    - 评委颗粒度下本次活动评审情况数据模型
  - 现有表
- 用户标签内容，可以算在现状梳理模块中（需要与业务方协商）（有点类似，数仓建设学习路线-数据资产建设内容，构建过程-规则制定过程）
  - 枚举值
  - 指标
  - 日期等

- 应用数据模型开发
  - ads_em_promote_evaluator_target_d
    - 数据表名称：ads层-晋升域-晋升过程汇总表-评委颗粒度
    - 应用侧模型建设内容（模型建设五要素，数据域——>主题域）
      - 颗粒度
      - 主题域
      - 派生指标（度量）
      - 维度
      - 分区（可以类比事实表类型）

    - 代码操作
      - 标签开发
      - 通过dwd判断组合方式、dws指标补充标签内容
      - 采用动态分区存储减少历史计算损耗

    - 表依赖
    - 建表DDL
    - 代码开发
    - 后继可能需要 考虑脱敏、数据质量、数据类型（行存储、Json、复杂类型）

  - ads_em_promote_dept_target_d
    - 有时候可以考虑指标下沉到dws

  - ads_em_promote_evaluator_target_d

### ADS-绩效域场景员工标签资产建设

#### 项目背景

语兴集团每年都会为员工绩效考评（分为A B+ B C），现在组织管理侧hr需要对全集团员工绩效分布以及绩效细节去深度查看，方便员工绩效改进，推进组织健康发展，从而赋能业务良性运营（因此本次hr看数的数据门户迭代和绩效域的接入合并一起开发形成一个项目）

#### 项目协同

项目协同：项目上游对接员工绩效系统库后端开发同学，下游对接数据产品（业务端、数据产品端）（对接需求，评估，对接口径。这次用数据产品视角去说）以及组织发展侧hr

<img src=".\image\ADS-绩效域场景员工标签资产建设.png" style="zoom:50%;" />

需求一般是业务方提出来的

#### 该项目数据产品职责

- 从数据仓库到数据产品:需求开发到需求管理
  - 1.数据仓库具备先天开发技能能够清楚需求能否实现，以及实现能力，但缺少产品系统化能力，以及需求指标沟通能力，但如果转产品后会比较轻松，就如语兴身边数据产品为例，原来也是数据仓库，但他却具备了很多产品没有的能力 
  - 2.清楚数据来源，并能梳理本次用到的数据表，能够让数仓同学知道数据来源信息减少数据找寻的问题。 
  - 3.清楚本次开发需求的人员，很多数仓同学对接业务或者后端时候不知道找谁，从而中间有很多周转。 
  - 4.清楚指标口径，这个点也是很多产品不具备的，没办法给予数仓同学具体的开发口径，但如果是数仓同学转产品，更快能清洗数据口径，甚至也能帮数仓同学开发伪代码。 
  - 5.能够帮助开发同学完成中间需求会开发并能理解业务诉求，从而减少数仓同学直接对接业务，或者中途开了大量无用的会而带来的需求延期。
- 方便整理好整体prd（产品需求文档），内容包括需求背景，需求预估价值，需求对接业务方技术方，绩效系统库的技术表梳理，整理好业务方需要的看的内容通过figma设计好整体样式，并沟通好业务口径并维护，最后配合ehr数据门户进行v1.7版本上线
- prd（细节内容都在prd里）：https://oxtwry26ao.feishu.cn/docx/Gm9odlhblo31Kux0EeachPhinYd?from=from_copylink
  - 需求背景
  - 需求价值
  - 功能模块&团队详情（分配任务）
  - 需求功能描述
  - 数据表梳理

#### 从整体视角去看业务流程及指标

##### 业务流程

绩效自评提醒->绩效自评->主管绩效点评->绩效申诉->绩效hr侧归档->绩效改进pip（performance improvement plan，绩效改进计划）

##### 指标拆解

与业务沟通需求，根据需求结合数分逻辑树拆解办法按照场景对绩效侧的指标拆解

**绩效板块场景**

- 绩效波动角度（是否存在大的绩效差距，评估员工能力及项目产出情况）
- 绩效申诉角度（是否有绩效冲突，绩效是否属实）
- 日常绩效角度（查看从入职以来整体绩效情况，形成趋势）
- 入职绩效角度（查看是否存在招聘事故，无法胜任融入环境）
- 入职较短时间角度（1.5年绩效情况，中长期员工绩效观察）

##### 模型建设（做DWD、DWM、DWS）

在沟通完指标后，开始梳理数据表，准备弄总线矩阵，梳理数据表，需要接入数据（ODS）。看有哪些字段，要用哪些字段。

- 搞ODS：导入的ODS数据，按业务数据库分库保存

- 搞DWD：有了ODS数据，可以开始准备搞DWD。之前要弄总线矩阵，划分数据域，按数据域构建dwd，首先要先建表，再插入数据。DWD可以做维度退化（维度下沉）
- 搞DWM，运行（第一次运行，现在没有上线）（Spark3运行）至此需求开发那一部分完成了，要开始搞需求质量校验了
  - 正面：维度好管理、业务方好理解（DWM可以对外透出）
  - 负面：耦合高，解决方法——拆成前中后（绩效前DWM、绩效后DWM）
- 提交上线，每个表都需要配置调度（包括依赖，可以看血缘）、（第二次运行，上线后）补数据、DQC、数据探查、数据比对

##### 应用模型建设（做ADS）

ads_em_mbo_emp_profile_d

- 数据表名称：ads层-绩效域-绩效场景标签数据资产（大宽表，可复用于后续不同维度下模型开发）
- 应用侧模型建设内容
  - 颗粒度：员工
  - 主题域：员工管理——绩效
  - 标签：是否长期低绩效、年度绩效结果、入职后首次绩效等
  - 维度：职级、职位、部门
  - 分区：天

- 代码操作
  - 标签开发
  - 通过构建wits as对dwd排序，组合等方式补充标签内容
- 表依赖
- 建表DDL
- 代码开发

##### 看板设计

这里只能用ads场景标签表去加工看板，如果再往下做部门/岗位/职级数据模型，在看板时会导致数据无法累加 

（1）如果做成ads部门指标表，例如筛选20240119 20240120两天去看员工绩效入池出池（2日均有低绩效入池出池的人数）则会出现数据累加不准确，因此只能用标签表再加工 

（2）可以按照分区做周期的指标统计，例如做月初月末指标统计，但这样仍不方便业务统计，但能实现ads表预计算

### ADS-盘点域

#### 员工九宫格，数分方法-二维象限分析

九宫格是什么？ 在评估员工绩效时，管理者通常会关注两件事：第一，他们今天的表现如何（即绩效）；第二，他们未来的表现将如何（即潜力）。例如，企业喜欢绩效优秀且潜力巨大的员工，以及工作很努力但潜力稍微逊色的员工；相反，低绩效、低潜力的员工可能会引起管理者的高度重视。 九宫格是以绩效和潜力为考量，对员工进行评估和分类以勾勒企业“人才地图”的实用工具。具体而言，它根据绩效和潜力两个维度建立3X3的矩阵，由此构成代表九类不同人群的九宫格。在使用时，根据员工绩效和潜力得分，将其划入不同的格子之中，以此作为人才盘点、制定人才发展计划的依据。 



ADS里的大宽表和小宽表的区别：大宽表，下游的依赖较多。而小宽表，下游的依赖较少


## 数据质量

具体可以见 ./数据建设学习路线.md 或者 ./数据建设学习路线.mind

这里主要瞅瞅：数据质量长期监测跟踪体系

### 数据质量长期监测跟踪体系

适合窄表

#### 介绍

- 由于上游数据经常出现数据质量问题情况，并常常暴露用户基础信息为空、部分字段存在逻辑问题的情景，使得下游同学使用起来较为困难，同时下游使用数据的同学对于隐藏的数据问题也不得而知，数据修复过程中进度也无法查知，所以需要数据质量长期监测跟踪体系来帮忙监控数据质量，从而达到上游下游都有感知情况。
- 不做这件事带来的危害：由于数据源头数据不是数仓侧能够修复的，但在业务方眼里出现数据问题统一会找数仓同学，从而最终还是数仓背锅，所以这块建设，不光是自发要去做，更要把上下游都拉入项目投入中。

#### 步骤

- 现状梳理：与BI沟通及数仓内部沟通罗列已存在的数据问题，并知会上游后端同学，完成存在的问题的验证与审核，将存在问题进行收集归类。

- 规则构建：将目前所有数据问题按照每个规则进行模块化规则配置，建设问题规则维度表（手工excel即可）为每个规则配置规则内容，包括规则类型、规则id/名、以及存在问题的字段/表、规则严重程度等。

- 治理数据模型设计/开发：建设相应DWD数据模型进行明细数据存放，from各类数据源ods（或者dim表）问题数据表，并做规则的维度退化，按照规则种类开设二级业务域（模型为二级分区，分区1为ds（业务日期），分区2为rule（规则））
  
  - 依赖：各类数据源、ods_dq_whitelist
  - 模型建设五要素
    - 颗粒度：员工、规则id（可以理解为主键，唯一独立存在）
    - 事实表类型：周期快照事实表（全量）
    - 数据域：数据质量
    - 度量值：暂无
    - 维度：部门等
  
  
  <img src=".\image\数据质量_数据质量长期监测跟踪体系.png" style="zoom:50%;" />
  每一个规则，点进去，类似下面
  
  ```sql
  insert overwrite table yx_dwd.dwd_dq_emp_base_detail_df partition (ds='${lst1date}',rule='001')
  select '001' as rule_id--问题规则id
    ,'性别是否为空' as rule_name--问题规则名称
    ,t0.emp_gender   as main_col1--字段1内容
    ,null   as main_col2--字段2内容 想要监控的字段2，原来长什么样
    ,null   as main_col3--字段3内容 想要监控的字段3，原来长什么样
    ,null   as main_col4--字段4内容
    ,null  as main_col5--字段5内容
    ,'main_col_1：性别' column_names
    ,'yx_ods.ods_yx_base_employee_base' as table_name--字段来源表
    ,t0.emp_id     --员工工号 
    ,t0.emp_type--员工类型
    ,t0.emp_state --员工状态
    ,t0.bu_name--bu名称
    ,t0.dept1_id--1级部门名称
    ,t0.dept2_id--2级部门名称
    ,t0.dept3_id--3级部门名称
    ,t0.dept1_name--1级部门名称
    ,t0.dept2_name--2级部门名称
    ,t0.dept3_name--3级部门名称
    ,case when t0.emp_gender is null or t0.emp_gender=''
    then 'Y'
    else 'N'
    end as is_trigger  --是否触发规则
    ,case when t1.emp_id is not null and t1.notice!='数据已修复'
    then 'Y'
    else 'N'
    end as is_whitelist--是否在白名单中
    ,t1.notice --治理回填内容(加白备注)
    ,'2023-07-14' as rule_start_date --规则新增日期
    ,'2023-07-15' as rule_end_date--规则下线日期
    ,null as rule_end_reason--规则下线理由
    ,'正常' as rule_state--规则状态
    ,t1.commitor_id as whitelist_commitor_id--白名单提交人
    ,t1.commit_time as whitelist_commit_time--白名单提交时间
  from  yx_dim.dim_emp t0
  
  left join yx_ods.ods_dq_whitelist t1 
  on t0.emp_id = t1.emp_id
  and t1.rule_id ='001'
  and t1.ds='${lst1date}'
  
  where t0.ds='${lst1date}'
  ```
  
- 数据应用（ADS）：建设ADS层规则颗粒度、治理人员颗粒度下规则触发情况与治理人员效果应用数据模型，用于看板侧对规则的触发情况进行阶段性统计以及人员治理工作量的评估。为啥不做DWS？因为DWS关键在于复用（业务复用情况比较多），但这个场景DWS很少复用，加长运行时长，没有必要

- 数据可视化：将各ADS应用数据传输至MPP数据库存储，通过网易有数搭建治理人效、规则触发波动、规则明细内容等看板搭建，并通过规则门户完成tab页的镶嵌

- 治理后的数据质量监控：经过上游对问题数据修复后，触发情况为0时，可将规则从模块下线，但保留规则编号与内容，并在其他数据源接入ODS层任务上配置DQC监控保障问题数据不会流入

已经有了ods_dq_whitelist表了，这张表是数仓自建。第三步会自动监控ods的数据，发现问题后，反馈给后端，后端修改好了，ods就问题就不大了，会填一张mysql表，mysql表会同步到ods_dq_whitelist。(数据质量长期监控体系是监控源头数据的，很早跑，ods（修改前）用于跑数据质量监控的dwd，跑完后，后端修改，修改后的ods用到其他业务数据域的dwd)
```sql
CREATE TABLE `yx_ods`.`ods_dq_whitelist`(
  `emp_id` string COMMENT '员工工号', 
  `rule_id` string COMMENT '规则id', 
  `notice` string COMMENT '治理回填内容（数据已修复、无需治理的问题，原因说明、无法治理，档案已销毁无法修复）', 
  `committor_id` string COMMENT '提交人', 
  `commit_time` string COMMENT '提交时间')
COMMENT 'ods层-数据质量长期监测跟踪体系白名单'
PARTITIONED BY ( `ds` string COMMENT '业务日期')
```

#### 应用数据模型开发

- ads_dq_committor_workload_target_d
  - 数据表名称：ads层-数据质量监控工作量化效果评估
  - 应用侧模型建设内容
    - 主题域：修复人员
    - 颗粒度：数据质量
    - 派生指标：问题解决数、问题复发数
    - 维度：部门
    - 分区：按日期分
  - 代码操作：指标开发（该内容不需要公共指标下沉，不用再开发一套代码引用）
- ads_dq_rule_target_d
- ads_dq_emp_target_d



## 元数据

具体可见 ./数仓建设学习路线

### 元数据介绍

简单来说就是描述数据的数据，包含数据的内容、结构、来源、格式、规则、质量等各个方面的信息，同时有了元数据信息可以方便后续的数据治理工作开展

- 基础元数据：库/表名、数据域、主题域、数仓分层、数据表owner、生命周期、文件路径、字段信息、创建日期、血缘
- 任务元数据：任务名称/节点、任务owner、任务创建人、调度信息、任务依赖、下游任务信息、计算引擎、执行时长
- 计算元数据：cpu消耗、memory消耗、消耗费用
- 存储元数据：物理存储量、文件、存储方式、压缩格式、记录行数

### 元数据管理

- 平台化
- 规范化
  - 表/字段
  - 模型评分
    - 模型质量评分：模型建设内容完善度考量（命名、被引用、生命周期等），并生成数据表存储，方便后续治理
    - 模型监控评分：根据最近X天规则触发情况给模型数据质量评分
  - owner：表/任务持有人注明
  - 元数据信息表建设
  - 数据血缘建设

具体见 ./数仓建设学习路线





## 指标体系

数仓很少做复合指标。一般做原子指标和派生指标

### 什么是指标？

指标是用来衡量、评估和描述数据的特征、性能或关系的度量标准。

### 指标类型（和标签区分）

标签：

- 枚举值
- 标签
- 日期等

指标包括原子指标（dwd度量）、派生指标（即dws、ads指标）、复合指标（即ads多指标组合呈现内容），通过指标能够去全面衡量数据信息。

- 原子指标：原子指标指的是基于业务过程的度量值，顾名思义是不可以在进行拆分的指标，如交易笔数、交易金额、交易用户数
- 派生指标基于原子指标、时间周期和维度，圈定业务统计范围并分析获取业务统计指标的数值，派生指标=原子指标+业务限定+统计周期+维度的组合（统计粒度），如交易金额的完成值、计划值，累计值等
- 符合指标：指建立在基础指标之上，通过一定运算规则形成的计算指标集合，如平均用户交易额、资产负债率、同比、环比、占比等

### 指标体系建设目的

与下游（风控/DA/数据产品/算法）达成合作，保障指标建设时口径的统一，完成指标覆盖，提升复用性，通过可视化方式提升查询效率

### 没有指标体系的问题

- 指标难找到：数据表较多，找指标如大海捞针如果只是用元数据去搜指标仍具有难度
- 指标无复用：由于没指标中心，开发者不清楚指标之前是否有开发，导致指标重复建设，最终出现烟囱数据表
- 指标口径难统一：开发的指标由于指标口径不一致，不同部门的业务方理解不一致导致指标出现二义性出现

### 指标中心建设

- 简易版：通过飞书等企业办公软件去维护在线excel文档，文档内容与指标中心新建指标图中一致（例如创建日期、创建人、业务/技术口径等），由于数据表较多，罗列起来较为繁琐，不建议直接放全部指标内容，简易放看板、报表中核心指标来实现
- 自建
- 商业

### 指标体系建设难点

- 能否与下游达成共识（沟通）
- 指标能否做到数仓收口：对外提供一个接口。多接口不好管理

- 需要与其他部门配合（数据平台/前端），进度难把控，容易烂尾
- 如何推广给下游
- 开发变更/下线规范难保障

### 指标更变/下线流程

- 指标更变：如果发现字段变更后对下游自己的表/报表产生影响，那自己负责修改代码并让其他同学进行代码审核、数据质量审核且任务运行成功后方可发布线上    如果下游血缘存在不是自己的表/报表，需要在相关业务群里说一下/找到下游表owner/报表owner发送通知，让下游owner进行修改，如联系不上需要向owner的leader说明问题，并且让下游表/报表的owner当天回复一下受不受影响，不回复则对方承担问题责任，如果对方不接受修改方案，需要双方约定一下修改内容、修改日期，重定方案。
- 指标下线：如果发现下游都是自己的表/报表，那自己负责将代码中的字段下线（字段下线不是删表从建，而是将字段置空等操作）并让其他同学进行代码审核，任务运行成功后方可发布,并且去除相应字段dqc检测（如果有该字段dqc的话）    如果下游血缘存在不是自己的的表/报表，需要在相关业务群里说一下/找到下游表owner/报表owner发送通知，让下游评估字段下线对下游的影响，如果评估没问题则让其进行代码中的字段下线，如联系不上需要向owner的leader说明问题，如果对方不接受字段下线，需要双方约定一下时间进行商讨。

## 数据安全

见 ./数仓建设学习路线

## 数据治理

见 ./数仓建设学习路线

治理岗位一般要求经验较高

### 数据仓库发展阶段

- 初始期：这个时期的业务特点往往是比较单一的，并且数据量相对较少。所以这个时期的核心诉求为快速支持业务团队包括数据分析、运营、风控等，更多是统一数据仓库内部规范，通过核心数据模型支撑下游应用。、
- 扩张期：这个时期的业务飞速增长，有大量的复合指标，派生指标会在BI、分析、算法等多个场景重复使用，需要数据仓库快速支持业务。这就需要数据仓库同学接入全部需要应用数据，完事中间层数据模型，同时保证数据的准确性，重点投入数据资产（离线/实时）建设。
- 治理期：在业务经历过快速扩张期后，就会步入稳增长的阶段的阶段，这个时候，不太需要大规模接入数据制作数据资产，重点在于对原有数据仓库进行治理降低数据使用成本（元数据维护、核心数据模型公共沉淀等）、降低计算/存储资源消耗、稳定任务产出、保障数据安全。
- 缓慢发展期：在经历治理期后，对于业务方更需要提效，这里提效指查数/用数的提效，能够让数仓内部和业务方更快定位指标、数据模型、用户数据等，实现自助查询，同时还可以开发一些效能小工具（问题代码自动识别、未被使用的数据模型/字段、智能报警监控等）实现自动化。

### 数据治理方向

**数据模型合规=计算资源>质量>存储>安全**

#### 数据治理工作台

建议大家在治理的开始把治理工作台做好，方便每个阶段评估，同时开放给下游业务方，让业务方也能看到成果（否则就是自己内部闭门造车对外看不到治理的价值），除了治理工作台外还可以每周/月给全技术/业务部门发送治理进度报告，让大家都有注意，有平台的同学直接用平台，没平台的同学建议搭建看板，展示每日采集的元数据信息（计算、存储、数据表内容等）

- 数据治理360

#### 数据模型合规治理（合规）

##### 数据模型合规治理背景

随着业务的快速迭代，同时数仓也在扩张期高速支持，产生的数据量越来越大，划分的数据域也愈来越多，但很多数仓在初步搭建时都没有确定好数据标准、模型设计规范、没有一套完整数据的生命周期管理体系、同时组内成员技术/业务水平质量参差不齐导致，从而导致烟囱数据表大量产生，无规范/无元数据维护的数据表让人无法看懂，数据表很难发挥出数据的价值（这里特指复用性），为了快速支持业务导致分层混乱（这里不代表非要做完数据表再去支持业务、而是在支持业务后能否沉淀资产）。

##### 数据模型合规治理流程及思路

 数据标准重制定->无用/临时数据表下线->应用指标公共下沉复用->解决ODS穿透问题->烟囱数据表重构及下线->元数据非合规数据表（包括元数据字段信息）修改。**（具体见语兴小灶）**

##### 治理之前如何评估

- 数据规范/元数据评估 （利用 元数据信息表）
  - 命名：首先需要统一命名内容，通过获取到元数据的数据表中的信息去评估。 
    - 表命名/表负责人/表注释：可通过数据模型进行Rlike 或正则去匹配表名，找到不符合规范的数据表去治理 
    - 字段命名/字段格式/字段注释等：如果能获取到字段元数据是最好，如果不具备条件，可通过数据地图优先评估核心数据模型

  - 数据/主题域评估
  - 规范自动化检测

- 无用数据表/临时数据表下线评估：数据血缘评估（到可视化血缘）
  - 读取热度、引用热度。
  - 无价值：没到ads，ads没被使用 

- ODS穿透评估：数据血缘评估（通常用ods到ads去参考）
- 烟囱数据表评估：同数据域/主题域，数据表重复加工，或者主题+颗粒度+维度一致数据表 但分开存放内容，其实完全可以合并，但这里需要人工去看，不能因为部分数据表指标重叠而认为是烟囱数据表，如果非要智能诊断，需要通过数据/主题域一致，且重叠内容较多去判断

##### 治理之后如何评估

- 这里更多是对于数仓内部的价值，对业务的价值是提升数据使用成本降低查数找数时间
- 数据模型标准合格率，由原来xx%提升至xx%，数据模型寻找时间从x小时降低至x分钟
- 下线各层无用/临时数据表总计xxx个，释放存储资源xxxxT；
- 完成xxx个应用层烟囱数据表整合，及xxxxx公共指标下沉，建设xxxx个dws/ads公共资产；
- ODS穿透率由原来xx%下降至x%；
- 数据模型合格分数平均高于xx分
- 与团队配合完成网易某业务线数仓数据表命名、字段命名、字段类型、数据表标注规范、数据表分区生命周期等6个方向规范制定

#### 计算资源治理（资源）

##### 计算资源治理背景

数仓开发经常会收到大量集群资源满载、任务产出延时等消息/邮件，甚至下游数分及其他同学也会询问任务运行慢的情况，在这里很多数仓同学遇到这类问题第一想到的都是加资源解决，但事实真不一定是缺少资源，而是需要优化当前问题任务。

##### 计算资源治理流程及思路

 参数调优&任务引擎切换->小文件治理->DQC规则治理->高消耗任务治理->调度安排->下线无用任务&公共指标下沉

具体见 **语兴小灶——计算资源治理**

##### 治理前如何评估

- 参数调优&任务引擎切换评估
  - 参数层面：根据任务元数据中的core、memory消耗，算出平均消耗，后续找到高于平均消耗任务配置不同参数
  - 任务引擎：根据任务元数据引擎中spark_version去查看，如无法采集元数据，需要人工去搜，较为麻烦
- 小文件治理评估
  - 小文件治理课程——见**语兴小灶**
  - 可以从hdfs目录去看,找到文件数较大的数据表路径去刷新
  - 也可以从元数据-数据表的文件数去看，去找top
  - 如果有平台也可以通过平台去看
- DQC规则评估
  - DQC资源分配情况
  - 对于自己配置的无效DQC下线，基础dqc中表不为空和表行数波动重复了（表为空即表行数波动为-100%），可以下线，对于业务DQC需要自己评估，长期不用的、没价值的可以下线
- 高消耗任务评估
  - 根据任务元数据中的core、memory消耗，算出平均消耗，后续找到高于平均消耗任务去优化，直到整体趋于原平均消耗值（可放宽）
- 调度安排：找到资源打满或水位线高于3/4的时段，通过任务元数据表梳理清楚当前时间段全部任务，可划分成核心任务和非核心任务
- 无用任务下线/公共指标下沉
  - 无用任务：和上述数据模型找寻方法一样，先通过数据表元数据找到无用&临时数据表，同时对于线上任务进行下线处理
  - 公共下沉：通过看板或者数据模型提取相同指标，对当前指标及数据表梳理查看应用层指标是否口径一致，如不一致需要与下游再次沟通后修改，梳理当前xxx主题域下应用数据表现状，明确需要被治理的目标，确认公共逻辑下沉与计算逻辑调优等核心问题。

##### 治理后如何评估

- 这里更多是对于业务和内部价值，对外价值是减少部门费用总支出、提升任务产出速度减少业务投诉，对内价值让任务运行更快减少资源互相争抢，削峰。
- （1）Hive与Spark2任务升级Spark3.1，总计升级任务x个,升级任务后总体任务执行效率提升43%，cpu资源消耗降低41%，内存资源消耗降低46%
- （2）治理小文件数大于xxxx以上的数仓表总计xxx张，小文件总数由xxxxw下降至xxxxw
- （3）下线无效DQC总计xxxx个，修改DQC配置资源降低运行时长，由原来10min优化至3min内
- （4）完成线上xxxxx个任务优化及xxxxx个任务下线及xxx个表指标下沉，优化后节省任务耗时xxx分钟，减少CPU损耗xxxx+，降低内存消耗xxxx+（相当于节省了8个200+字段1亿数据量任务消耗）
- （5）调度重新分配后2-5点资源使用率由90+%降低至50+%，保障日用资源趋势图无大突刺波动
- （6）整体治理后为部门减少1/3总费用，由原来的xxxx万元降低至xxxx万元
- （7）数据产出平均时间由原来每日最晚9:30产出降低至7:10；

#### 存储资源治理（资源）

##### 存储资源治理背景

由于早期数仓在存储资源充足情况下，未考虑到后续扩容和存储格式问题导致后续存储资源紧张，从而需要整体治理

##### 存储治理流程及思路

 下线无用数据表节省存储->存储格式及压缩格式配置->设置统一表及分区生命周期->根据业务情景实现节省存储**（具体见语兴小灶）**

##### 治理之前如何评估

- 无用数据表评估：方法和上述数据模型合规治理方法一致
- 存储格式及压缩格式评估
  - 通过数据地图单独查看
  - 查看元数据
- 表及分区生命周期评估
  - 模型分区生命周期：
    - ODS：365or1095天-1或3年 
    - DWD：1095天-3年 
    - DWS：1825天-5年 
    - ADS：1825天-5年 
    - DIM：非用户维度可存放10年、用户维度建议用拉链表
  - 临时表生命周期为7或30天，非线上调度引用
  - 生命周期评估方式
    - 通过数据表生命周期去查看
    - 数据地图
    - 数据治理360生命周期诊断
- 根据业务情景实现节省存储评估：此处需要单独去看数据存储top所使用的存储方式（例如全量）

##### 治理之后如何评估

- 这里更多是对于业务和内部价值，对外价值是减少部门费用总支出
- （1）下线各层无用/临时数据表总计xxx个，释放存储资源xxxxT；
- （2）使用Parquet格式+Snappy压缩，提升压缩比，存储资源由原来xxxxT降低至xxxxT
- （3）统一生命周期节省不必要的存储资源，对于临时表采用7天表存储生命周期，对于每一分层、业务进行统一裁剪，存储资源由原来xxxxT降低至xxxxT
- （4）根据不同业务场景，通过拉链表，增全力量方式存储存储资源由原来xxxxT降低至xxxxT
- （5）整体治理后为部门减少1/3总费用，由原来的xxxx万元降低至xxxx万元

#### 数据质量治理（合规）

##### 数据质量治理背景

这里数据质量治理前提是已经做过数据质量规划，如没实施数据质量方案需要先去部署，存在的问题包括sla及基线经常破线、dqc经常触发、仍被下游用数方投诉较多数据质量问题

##### 数据质量治理流程及思路

 修复并治理当前破线较多的SLA/基线->对DQC及任务进行系统化治理（波动自动化算法识别、经常告警DQC处理）->对原有下游提来问题提出共通性去修复->提升团队成员对数据质量重视**（具体见语兴小灶）**

##### 治理前如何评估

- 基线/SLA破线：基线可以通过基线运维去查看每日/近一周基线破线情况,每条基线周破线次数,夜间电话告警次数,起夜次数等判断基线情况,SLA破线可从与业务方对接,对数仓产出投诉去查看。
- DQC及任务失败频出：可根据DQC频发次数，任务失败次数等情况去判断，或某个任务导致经常起夜查看，这里DQC频发不一定是DQC有问题，很大概率都是数据波动，数据分布略高/低导致
- 数据质量问题频出：通过下游在问题上报平台、需求平台（数据质量问题记录）、共享excel等找到共通性频发问题去统一治理，或者查看其他数据表是否存在此类情况，对于数据源头问题需要把问题放入长期跟踪检测体系中去运维 可以从数据质量问题出发，找到任务经常出现数据质量问题对应的数仓同学，指定奖惩及培训措施降低问题发生

##### 治理后如何评估

- 这里更多是对于业务和内部价值，对外价值是数据问题更少发生，任务更稳定
- （1）通过对基线/SLA治理，夜间值班培训及手册，保障核心任务按时产出，原每周3天不能准时产出降低至小于等于1天；
- （2）对DQC及任务治理系统化治理，自动化配置，保障夜间值班同学起夜率降低至xx%
- （3）通过对原有业务方提来的bug找到共通性问题，同时加强数仓团队数据质量理念，制定奖惩措施，数仓侧原有bug从每月40-50个，降低至每月小于7个

#### 数据安全治理（合规）

##### 数据安全治理背景

这里数据安全治理前提是已经做过数据安全规划，如没实施数据安全方案需要先去部署，存在敏感数据泄露、数据安全审批节点过长、风险数据对外暴露、数据使用权限（表、库）闲置情况。

##### 治理前如何评估

- 数据安全问题出现评估
- 数据表审批链路评估
- 数据权限评估
- 闲置数据使用权限评估

##### 治理后结果怎么评估

- 这里更多是对于内部价值，对内保障数据安全问题不再发生。
- （1）数据安全问题发生次数（包括跨部门申请表、下载数据等）由x次降低至x次
- （2）缩短数据表/字段申请链路，增加审核卡点必要申请说明，由原来x小时申请时间缩短至x小时。
- （3）对原数据权限再管控分配，保障数据使用权限，可视化查看权限，数据下载权限等x块内容安全
- （4）对近xx天存在表权限闲置做整体监控，总计收回xxx张表数据权限，保障闲置权限能及时收回



## 实时技术

### 实时开发建设背景

随着业务发展对于数据实效性要求较高，同时对于直播、工业数据等实时场景较多业务需要依靠实时技术来提供支撑，业务方可以通过实时数据达到实时决策效果。

### 项目招聘域实时链路建设

####  招聘域建设流程

- 招聘岗位发布
- 招聘渠道
- 简历
- 应聘
- 面试
- 招聘体验
- 体检
- offer
- 背调

#### 项目背景

当前公司对于人才招聘好坏的实效性要求提高，通过实时招聘数据为业务提供面试实时进度分析，好对于面试、offer进展进行规划以及通过面试反馈得分做好面试官的甄选。

#### 本次用到的架构及组件介绍

- 架构——Lambda架构
- 组件
  - 数据传输——FlinkCDC
  - 计算引擎——Flink（1.14）
  - 中间件——Kafka
  - olap——Doris
  - 数据平台——网易easydata
  - 数据源——MySQL、Hive

- 数仓分层
  - 这里分层与离线数仓类型，但由于业务场景实时指标较少，同时考虑到实时链路，对于DWS建设剔除，对于不同业务可考虑开发公共DWS层模型
  - 准备事项
    <img src=".\image\实时数仓分层准备事项.png" style="zoom:50%;" />
  - 实时数仓分层
    <img src=".\image\实时数仓分层.png" style="zoom:50%;" />

##### 实时开发流程

- 数据接入
  - 整体流程：通过数据同步工具flink cdc、将业务库mysql的binlog数据接入中间件Kafka的Topic中 并通过实时平台配置完成实时ODS流表（读取Topic内容（像视图））同步
  - 流表建设
    - 流表介绍：流表即读取数据源的表，流表不存放数据，只是对于数据存储的映射，可以理解为视图
    - 流表建设流程：首先配置好流表的数据源，进入实时数仓表管理，新建流表库，再新建流表,建设时可选择绑定主键（后续用于数据刷新覆盖）、水印、序列化方式、同步的topic等
  - FlinkCDC任务：Flink CDC任务建设跟离线类似也是通过文件夹新建任务，新建后可选source和sink，并将mysql的binlog数据打入流表中，并可以给任务配置相应参数。（FlinkCDC会将监控mysql，变动的数据会在中间件中出现）
  - ODS流表结构（具体见数仓建设实践路线.mind）
- 实时数据模型建设
  建设整体步骤：通过实时平台及计算引擎Flink对ODS数据进行Join、清洗、转换、过滤、聚合、维度退化等（模型规范依旧采用之前建设思想） 完成DWD、DWS、ADS流表模型设计，设计原理与离线数仓一致
  模型建设建设步骤：
  - 设计数据模型的流表：与ODS方式一致新建DWD、DWS、ADS流表库，再建设流表，这里要注意流表命名要与离线区分，比如尾缀离线增量是di，实时是ri，ads离线尾缀是调度周期比如_d，实时是不需要的。
  - 实时代码开发：与新建Flink CDC任务一致，可选择SQL or JAR的方式开发，本次我们选择sql开发，sql模式可以sql写数据表映射语句再插入数据实现，或通过选择source、sink，通过流表实现(选择消费者组绑定流表，只需要写sql即可)
  - 实时任务配置：通过设置checkpoint和重启策略以及资源完成任务配置
  - 数据校验
    - 根本是解决实时离线数据无法保持一致
    - 1统一指标口径，同时复用指标中心逻辑 2保障数据来源一致 3拉消费点位跟离线比对4采样比对

  - 实时任务运维
    - 对于大促活动下实时大屏需要压测（一般为2次以上）
    - 实时运维和Flink UI即一套内容，可通过日志中fail over 以及告警信息定位问题以及瓶颈,找到任务问题节点
    - 实时监控：实时也有DQC，但与离线不同的事监控的内容,1任务失败2.数据延迟3. failover次数（感觉还可以补一个资源水位线的告警）

  - 代码及表结构


#### 数据应用/可视化

将ADS流表sink到OLAP/mysql/habse中存放，通过实时大屏工具（可通过阿里云Quick BI、DataV、网易有数、Finereport）对ads数据进行展示

- 数据落地
- 大屏展示

#### 实时链路优化

（具体见.\数仓建设学习路线.mind）

- 调优目的：让任务在目标峰值RPS下，无延迟，且集群资源利用率在合理范围内
- 优化思路：见.\数仓建设学习路线.mind
- 并发调优
- 内存调优
- 维表关联调优：Async+partitionjoin+缓存 原始的维表 JOIN 是同步访问的方式，来一条数据，去数据库查询一次，等待返回后输出关联结果。可以发现网络等待时间极大地阻碍了吞吐和延迟。为了解决同步访问的问题，异步模式可以并发地处理多个请求和回复，从而连续的请求之间不需要阻塞等待。 目前 HBase 提供三种缓存策略，分别是 None， LRU， ALL。 None: 无缓存 LRU: 最近使用策略缓存，需要配置相关参数：缓存大小（cacheSize）和 缓存超时时间（cacheTTLMs） ALL: 全量缓存策略。即在 Job 运行前会将远程表中所有数据 load 到内存中，之后所有的维表查询都会走 cache，cache 命中不到则不存在，并在缓存过期后重新加载一遍全量缓存。

## 数据服务

### 数据服务概念介绍

- 通过数据平台的功能为下游提供应用服务，解决数据仓库、数据分析、企业中数据共享、风控策略、产品应用和算法侧的痛点，使得用数难、找数难、数据出口繁杂的问题得以解决，可以理解为通过数据产品建设，提升数据仓库内部，以及下游用数效率。 


  数据服务举例 指标混乱下游不清楚指标具体业务口径、技术口径、指标来源、每次咨询数据仓库同学都需要等待1-2小时才能解释清楚，同时数据仓库同学也并不一定能及时回答，可能会造成等待的误会，同时数据仓库同学每周回答问题也会降低开发投入，因此需要指标中心统一维护指标、降低查询难度、规范化指标存放，最后达到的效果1.实现用户自助查询原来需要1-2小时等待 现在5分钟内可以定位2.有了统一存放平台更方便管理，包括指标上下线流程，减少重复指标建设，降低烟囱开发。

- 数据服务的业务价值，即为下游或内部开发同学查数/用数提效。 


  查数/用数提效为业务方提升了更快的效率，能够快速找到并使用数据，在这里数据仓库侧需要对元数据维护、定制相关提效数据服务（数据资产门户、指标中心、ONE-ID等），通过数据服务以及元数据维护将查数/用数成本降低，将原业务方几小时查询及询问时长降低至分钟内自助查询定位（例如原来业务方自己找数据表 查询指标要3小时，现在能够实现自助查询，并能再5分钟内定位），极大降低了成本，同时减少了数据仓库侧问题答疑次数，达到快速定位效果。

### 当前数据应用时存在的痛点

- 指标和标签口径无法统一维护：
  - 指标和标签的口径不统一会导致下游数据质量问题，进而影响下游应用分析。此外，当下游频繁更改指标内容时，未能及时通知他人也会导致应用问题的出现。
- 指标及标签口径无法通过平台化去查询
  - 当前指标和标签无法提供可视化查询，下游可能不清楚查询地址，增加了数据仓库的查询负担。同时，数据仓库开发者在开发指标和标签时，由于缺乏已有内容的可见性，可能会出现重复建设的情况，造成不必要资源浪费和人力投入。
- 想查询的数据模型无从找寻：数据地图解决了数据模型中元数据查询问题，由于缺少数据仓库侧元数据内容划分，数据仓库开发者和下游在查询时可能会面临较高的开发成本和较低的查询效率。
- 数据准确性缺少保障服务：数据仓库开发者在代码上线前后缺少保障节点，导致问题数据流入下游。
- 数据缺少安全保障服务：由于缺乏统一的数据模型和字段权限管理、数据脱敏和安全分级管理服务，数据仓库开发者可能存在部分敏感数据流出或被查看的情况，从而带来安全隐患。
- 数据模型缺少统一建设服务：数据模型在被设计时候常常出现与现数据标准无法对齐，数据模型冗余较高，耦合性高，复用性扩展性较差情况，需要强制数据模型审核机制，以及建设数据模型时标准自动化服务来解决此类问题。
- 用户画像无法自助分析：下游数据分析、风控策略和运营人员无法灵活使用自动生成的用户标签对应的客群分析，导致数据仓库侧和下游人员的工作量增加，效率较低。
- 存在各类ID无法相互打通与统一：随着业务拓展各类应用场景ID种类暴增，同时带来各类ID无法打通，最终形成“数据孤岛”问题，导致业务应用时困难重重。
- 数据治理内容难全方位评估：随着数据仓库经历过扩张期暴涨后，数据模型、计算及存储资源、数据质量、数据安全、数据价值等都会出现相应问题，存在数据仓库开发者不知道从哪找到切入点，且治理效果展现等问题。



### 数据服务建设内容

- 指标中心
  - 指标中心介绍：解决指标统一管理存放问题，统一指标口径，保障已有指标直接取逻辑复用，即使下游应用方不清楚指标内容，也能高效了解指标含义。
  - 搭建流程：
    - （1）明确指标中心分类内容及板块： 首先需要明确指标的分类和指标域（用于关联数据域），技术口径与业务口径，修饰词（用于派生指标指标和复合指标定义，不含计算口径）与衍生词（用于修饰原子指标，带有计算口径），同时还需要给指标补充重要等级、上线时间及负责人保障指标开发能精确到每一人
      注：这里要提一下，很多同学对于接到指标中心这个项目不知道怎么拆解，语兴提供大家一个思路，第一期可以优先找出核心指标，既然没有头绪，我们从能看到的地方去找（1）核心指标看板指标（2）梳理出常用top看板/ads数据表中重叠指标（需要借助元数据或者自己扒代码或查看元数据），这里一定是同域/跨域，同颗粒度的指标 第二期可以根据常用的域把业务频率使用高的指标补充进指标中心。
    - （2）功能开发： 完成指标中心各个模块（创建、编辑等）及搜索跳转功能开发，并创建后台数据库及指标内容数据模型用于后续数据存放，后续还可添加指标审批和指标更新后消息提醒，再与前端开发团队配合完成可视化界面搭建或自己完成开发。 由于数据仓库开发者可能不具备如上资源或能力，亦可通过低代码方式完成平台搭建，或通过可视化内容嵌入门户的方式搭建简易指标管理中心。

- 标签/画像管理平台
  - 标签画像管理平台介绍：解决标签无处找寻、用户画像无法自助分析的问题，帮助下游快速对标签定位，通过灵活组合方式形成多种画像用于高效分析用户客群。
  - 搭建流程
    - （1）明确标签画像平台功能： 与指标中心相似，明确标签应用的业务场景（主题）和颗粒度分类，技术口径与业务口径，同时还需要给指标补充重要等级、上线时间及负责人保障指标开发能精确到每一人。 梳理圈选标签时标签类目，考虑到用户体验，可让用户在圈选前进行标签1-3级分组设定，并通过TAB分离标签种类（复合标签、行为标签、基础标签等），并筛选标签逻辑（交集、并集、补集）。
    - （2）功能开发： 标签管理类似于指标中心，需要完成标签中心的各个模块（如创建、编辑等）和搜索跳转功能的开发。同时还要创建后台数据库和指标内容数据模型，以便存放后续的数据。还可以添加标签审批和标签更新后的消息提醒功能。 画像圈选开发难度较大，但底层逻辑仍为SQL调用，例如要查询A与B标签下都为1的用户群体调用则是select user_id from test where a=1 and b=1;,通过筛选标签去执行后台SQL。 由于数据仓库开发者可能不具备如上资源或能力，亦可通过低代码方式完成平台搭建，或通过可视化内容嵌入门户的方式搭建简易标签管理中心，画像圈选建设建议交予数据平台侧建设。

- 数据资产门户
  - 数据资产门户介绍：数据资产门户提供了查询自助化功能，解决了数据仓库侧及下游在各数据域下找不到对应环节下数据模型/核心数据模型的问题。这一改进消除了因下游找不到对应数据模型而需要多次与数据仓库同学沟通的情况，从而提高了开发及应用效率。
  - 搭建流程：
    - （1）数据资产门户设计：明确数据资产门户要准备哪些给服务于当前场景的内容，可以对数据模型的元数据全部展示、亦可通过元数据对当前数据模型按照分层关系、数据域、主题域区分
    - （2）元数据信息采集：建议通过使用三方工具Apache Ambari、Apache Atlas、等对Hive元数据信息收集，并后续存储在数据模型中存放，并可以根据数据模型进行重要等级打标，给予表检索及使用热度，这里建议使用DataHub开源数据中心，DataHub提供了可扩展的元数据管理平台，可以满足数据发现，数据可观察与治理。这也极大的解决了数据复杂性的问题，地址：datahubproject.io
    - （3）通过API方式将数据模型信息给予前端，配合完成数据资产门户搭建，或通过报表开发方式展示。

- 数据模型设计中心
  - 介绍：数据模型设计中心实现了主题域和分层自助式设计，统一了数据模型命名标准（例如词根和分层命名前后缀），并提供了可视化操作方式以完成数据模型设计。此外，数据模型设计中心还设立了强制性的数据模型审核机制，以确保数据模型易用性、规范性 由于实施起来难度较大，这里数据模型设计中心建设需要交予数据平台开发者。

- One-ID
  - One-ID主要通过数据模型建设解决随着业务分散及多场景下ID多样化无法统一使用及查询的问题，例如某数据模型A只有user_id, 某数据模型B只有工商注册号，但无法打通A与B之间关联，让下游查询及使用时困难重重。 
    同时one id更适合一些大厂不同部门之间数据连通，带来用户增长同时也能带来营销的增益，例如最近网易在把网易云音乐、网易严选、网易游戏等user_id打通形成集团统一的one id最终使得不同部门都能合作共赢
  - 搭建流程：通过数据模型之间关联ID关联设计One-ID维度表存放每个用户全部ID类型数据，通过关联扩散方式将应用层数据模型内容统一带上唯一的ID，例如user_id（原ID仍存在），也可算法工程师提供ID扩散表方式、亦或者三方渠道购买工具方式将ID整合一起，通过统一user_id查询出对应数据。

- 数据治理360
  - 数据治理中心介绍：数据治理360是一款大数据评估和优化工具，可从数据质量、标准、安全、成本和价值五个方面进行数据治理，协助企业优化存储成本和节约计算资源。此外，该工具还提供精细化的数据管理和备份功能，帮助企业更好地管理。 由于实施起来难度较大，这里数据治理360建设需要交予数据平台开发者。

- 数据服务
  - 数据服务（api）背景：在我们开发过程中经常会遇到把数据回传的数据库，或者被其他部门调用情况，这时候需要提供api给到合作方，但数仓同学更多缺少这块能力，所以缺少能自动生成api的效能小工具提供帮助。


### 数据服务建设周期

好多同学可能会想到数据服务到底什么时候开展最好，其实数据服务建设跟数据治理一样更偏向后期数仓建设时，尤其是数据治理阶段都做完后，对于数仓侧来说更缺少产出，这时可以介入数据服务建设，语兴在这里为大家提供2个建设时期。

- 探索期：在探索期，数据仓库需要充分了解业务流程环节，并制定数据标准和架构，划分主题域和数据域，以支持业务核心指标。因此建议在探索期建设时补充指标中心和数据资产门户，以保障核心指标与数据模型能够及时查询及了解。
- 治理期：在治理期最重要则是体现治理的价值（降本、质量、模型合规等），可以通过提前建设数据治理360门户提供内部及下游使用，后续同可以用于汇报
- 变革期：在变革期，由于数仓在业务产出较低，需求也同时较少，因此需要从提效角度去出发建设数据产品支持业务快速用数，同时在这里需要组内能有产出，需要变革期建设数据服务。







