配合 .\数仓建设学习路线.xmind

# 认识数仓

数仓：面向主题、集成的、相对稳定的、反应历史变化数据的集合，用于支持管理决策

数仓定位定位**（采建管用）**：承接各种数据源，通过采（对数据源数据采集）、建（数据资产/模型建设）、管（数据管理、数据服务）、用（如何利用数据为下游创造更多应用价值分析）的方式实现下游需求内容为数据分析、运营、风控等业务提供数据支撑

数仓建设内容大图及简介

<img src=".\image\数仓建设内容大图及简介.png" style="zoom:67%;" />

组件：

- 关系型数据库
- 存储库
- OLAP
- 元数据管理
- 中间件
- 调度
- 数据抽取

架构：

- HSAP
- Lambda
- 流批一体
- kappa架构

# 数仓模型建设

OLTP与OLAP

## 数仓分层

为啥要分层？

- 清洗数据结构
- 数据血缘追踪
- 减少重复开发
- 把复杂问题简单化

分层内容 （有点旧了，比较新的建模可以看..\实战项目\yshopping\yshopping项目文档.md）

- ods层
- dwd层：先要搞出数据域，主要干清洗，字段命名规范等，也可以做维度退化，维度退化也可以到dwm做
- dwm层：是对DWD层的生产数据进行轻度综合和汇总统计(可以把复杂指标前置处理），提升公共指标的复用性，减少重复加工。
- dws层： 按照数据域、颗粒度（例如买家、卖家）划分，按照周期粒度、维度聚合形成指标较多的宽表，用于提供后续的业务查询，数据应用，最重要一点需要在DWS层完成指标口径统一及沉淀
- ads层 ：按照主题域，颗粒度划分（例如买家、卖家）划分，按照应用主题将对应数据标签补充至应用层，最终形成用户画像及专项应用

## 数据模型

### 什么是数据模型

数据特征的抽象，通常包括数据结构、数据操作、数据约束。

- 业务模型
- 概念模型
- 逻辑模型
- 物理模型

### 数据模型建设方法

#### 维度建模

- 星型模型
  - 概念：因为数据的冗余所以很多查询不需要做外部连接，因此一般情况下效率比雪花模型高，设计与实现比较简单
  - 特点：
    - 只需要确定主键
    - 不需要在外部进行连接，大大提高性能实现高度并行化
    - 容易理解，只需要看关联条件和血缘关系就能确定模型
- 雪花模型
  - 概念：由于去除了冗余，有些统计就需要通过表的连接才能产生，所以效率不一定有星型模型高。因此在冗余可以接受的前提下，实际运用中星型模型使用更多，也更有效率
  - 特点：
    - 需要主外键来确立管理
    - 雪花模型在维度表、事实表之间的连接很多，因此性能方面会比较低，不能并行化
    - 过多的连接使得开发和后期维护都增大难度

#### 三范式建模

旧

#### 三范式与维度建模区别

略

### 模型建设具体流程

- 模型设计基本原则
  - 高内聚低耦合
  - 数据可回滚
  - 公共逻辑下沉
  - 规范一致性
  - 可拓展
  - 成本与性能平衡
- 维度建模设计大图

<img src=".\image\维度建模设计大图.png" style="zoom:67%;" />

- 模型建设过程
  数据域划分：面向业务SOP（标准操作流程）
  构建总线矩阵：维度为列，业务为行

<img src=".\image\模型建设过程.png" style="zoom:50%;" />

现状梳理：弄清楚SOP，划分数据域，构建总线矩阵

- 总线矩阵：指以一致性维度为列，以业务过程为行，构建业务的数据矩阵，通过标记表示该维度与业务过程的相关性
- 模型建设考量5要素（重点）（！！！！！！！！！！）：
  - 数据域：对当前业务场景或业务sop进行拆分完成建设
  - 事实表设计：围绕着业务过程来设计，通过获取描述业务过程的度量来表达业务过程，包含了引用的维度和与业务过程有关的度量。
  - 维度：对当前场景描述及补充
  - 颗粒度：数据域下场景用户再进行细致拆分（例如用户可拆分为买家或卖家），颗粒度必须拆分为不可拆分的状态（例如用户拆分为买家，买家不可拆分）
  - 度量值：对场景下数值类型的数据记录

### 模型数据域

- 概念：指面向业务分析，将业务过程或者维度进行抽象的集合。其中业务过程指企业活动中的事件，例如下单、退款、加购等，维度即度量的环境，例如下单事件中的买家。
- 举例：
  <img src=".\image\数据域举例.png" style="zoom:50%;" />

- 跨数据域：背景：例如DWS、ADS出现跨数据域（例如该模型既用于风控又用于用户画像）情况，需要根据跨的数据域再重新定数据/主题域。可以考虑再开一个数据域，公共域

### 事实表设计

- 概念：围绕着业务过程来设计，通过获取描述业务过程的度量来表达业务过程，包含了引用的维度和与业务过程有关的度量。
- 事实表类型：
  - 事务性事实表：更多应用于DWD层。
    对于单事务事实表，一个业务过程建立一个事实表，只反映一个业务过程的事实 
    对于多事务事实表，在同一个事实表中反映多个业务过程。
  - 累计快照事实表：更多应用于DWD层。累计快照事实表 对于类似于研究事件之间时间间隔的需求,采用累计快照事实表可以很好地解决，如在统计买家下单到支付的时长、买家支付到卖家发货的时长等。
  - 周期快照事实表：更多应用于DWS层。在确定的时间间隔内对实体的度量进行抽样，用于研究一段时间内实体的度量值（例如近30天pv、uv）
  - 三者对比：
    <img src=".\image\事实表种类对比.png" style="zoom:50%;" />

- 事实表设计过程：识别业务过程->选择事实表类型->声明颗粒度及维度->补充主题域下度量值->维度退化

- 拉链表
  - 概念：记录历史数据，记录一个事物从开始一直到当前状态的所有变化的信息
  - **拉链表是一种用于记录和处理历史变化的特殊表结构，它通常作为“维度表”来使用，而不是“事实表”。**
  - 拉链表制作背景：数据量大、表中部分内容会更新、每天保留一份全量数据、维度表的缓慢变化等
  - 拉链表设计
    - 加行：为明细表添加两个字段一个字段为拉链的开始日期（默认为用户数据出现的日期），另一个字段为拉链的结束日期（默认为9999-99-99），当一个客户a信息变更则添加一条新数据，新数据的拉链日期为更新日期，结束日期为9999-99-99，而原来的结束日期为当天更新日期
      <img src=".\image\拉链表_加行.png" style="zoom:50%;" />
    - 加列：为明细表添加四个字段一个字段为拉链的开始日期（默认为用户数据出现的日期），一个为拉链结束日期，一个为第二个段拉链开始日期（默认9999-99-99），一个为第二个段拉链结束日期（默认9999-99-99），当原数据更新时候，原第一个拉链日期不变，第一个拉链结束日期为数据变更日期，第二个日期开始时间为数据更新时间，第二个结束日期不变。
      <img src=".\image\拉链表_加列.png" style="zoom:50%;" />
- 举例：识别业务过程->选择事实表类型->声明颗粒度及维度->补充主题（数据）域下度量值->维度退化
  <img src=".\image\事实表设计举例.png" style="zoom:80%;" />





### 数据模型命名规范

见..\实战项目\yshopping\yshopping项目文档.md

### 数据模型发展周期

<img src=".\image\数据模型发展周期.png" style="zoom:80%;" />

# 元数据管理与指标体系

见  .\数仓建设学习路线.xmind

## 什么是元数据

描述数据的数据

## 元数据如何管理

### 工具化

- 开源
- 平台
  - 数据地图
  - 数据资产门户：对主题域、数据表、归纳、提升下游使用效率

### 规范化

#### 表/字段

- 表/字段注释
- 表字段命名：第二讲
- 字段主键注释
- 字段类型统一
- 表/字段血缘
  - 表数据链路模型：表之间的依赖关系
  - 字段全链路模型：字段之间的依赖关系
- 模型/字段热度
  - 读取热度
  - 引用热度
  - 收藏热度
  - 检索热度
  - 是否核心表
- 表属性
  - 维度表
  - 事实表

#### 模型使用说明

#### 存储规范

- 分区合理化
- 小文件处理
  - 使用spark3自动小文件合并
  - key打散减少reduce聚合
  - where过滤少量的key
  - map join
  - 参数调优 shew join（跳过热点key）
  - 从源头解决小文件合并问题
- 存储类型
  -  ORC
  - parquet

#### 模型评分

- 模型质量评分：模型建设内容考量
- 模型监控评分

#### Owner

- 表持有人
- 表使用者权限

#### 元数据信息表建设（具体见实践路线）

- 存储资源元数据+基础元数据表
  ```sql
  CREATE TABLE `xx`.`dwd_meta_table_detail_df`(
    `cata_log` string COMMENT '集群or数据源', 
    `db_name` string COMMENT '库名', 
    `table_name` string COMMENT '表名', 
    `join_name` string COMMENT '关联用name', 
    `layer` string COMMENT '分层', 
    `creator` string COMMENT '表创建人id', 
    `creator_name` string COMMENT '表创建人姓名', 
    `comments` string COMMENT '表描述', 
    `table_update_time` string COMMENT '表同步时间', 
    `tbl_type` string COMMENT '内部/外部/视图', 
    `tbl_inputformat` string COMMENT '表的inputformat', 
    `tbl_outputformat` string COMMENT '表的outputformat', 
    `tbl_loc` string COMMENT '表的存储位置', 
    `tbl_owner` string COMMENT '表的负责人：可选值为项目/用户', 
    `file_total_fromfile` bigint COMMENT '文件总数: 计算方法为根据表所在的路径的文件信息统计得到', 
    `size_total_fromfile` double COMMENT '存储量:这里是逻辑存储量，未考虑副本，单位为MB；计算方法为根据表所在的路径的文件信息统计得到', 
    `file_add_fromfile` bigint COMMENT '新增文件数:计算方法为昨天的文件总数-前天的文件总数', 
    `size_add_fromfile` double COMMENT '（根据文件）新增存储量:单位为MB， 计算方法为昨天的文件规模-前天的文件规模', 
    `open_total` bigint COMMENT '文件打开次数：计算方法为从底层取open_add_all字段', 
    `audit_total` bigint COMMENT '所有操作的执行次数：计算方法为从底层去audit_add_all字段', 
    `open_lasttime` string COMMENT '文件的最后打开时间：计算方法为底层取open_lasttime_max字段', 
    `audit_lasttime` string COMMENT '文件的最后操作时间：计算方法为底层取audit_lasttime_max字段', 
    `tbl_create_time` string COMMENT '创建时间', 
    `tbl_creator` string COMMENT '文件的创建人', 
    `partition_tbl` string COMMENT '是否是分区表', 
    `tbl_ref_num` bigint COMMENT 'job，query引用的job个数（注意开发模式和任务模式的job算两个）', 
    `tbl_visit_num` bigint COMMENT 'job,query的访问次数', 
    `account_id` string COMMENT '项目ID', 
    `catalog_id` string COMMENT 'catalog_id', 
    `catalog_name` string COMMENT 'catalog_name', 
    `catalog_type` string COMMENT 'catalog_type', 
    `refer_count` bigint COMMENT '引用次数(元数据中心)', 
    `read_count` bigint COMMENT '读取次数(元数据中心)', 
    `storage_type` string COMMENT '存储格式', 
    `lzo_compressed` string COMMENT '是否是lzo压缩', 
    `impala_sync` string COMMENT 'impala 同步情况', 
    `last_modified_time` bigint COMMENT '变更时间', 
    `transient_last_ddl_time` bigint COMMENT '表变更时间', 
    `lifecycle` string COMMENT '表生命周期', 
    `partition_lifecycle` string COMMENT '分区生命周期', 
    `themedomain` string COMMENT '主题域', 
    `domainlevel` string COMMENT '表分层', 
    `changetimes` bigint COMMENT '修改次数', 
    `cpu_cost` double COMMENT 'cpu消耗', 
    `memory_cost` double COMMENT '内存消耗', 
    `file_average_size` double COMMENT '文件平均大小', 
    `file_add_fromfile_30` bigint COMMENT '30天新增文件数', 
    `size_add_fromfile_30` double COMMENT '30天新增存储量', 
    `open_total_30` bigint COMMENT '30天文件打开数', 
    `cpu_budget` double COMMENT 'cpu 元', 
    `memory_budget` double COMMENT 'memory 元', 
    `storage_budget` double COMMENT 'storage 元', 
    `offline` string COMMENT '是否下线', 
    `unvistied` string COMMENT '30天无访问', 
    `tbl_owner_email` string COMMENT '表owner email', 
    `changetimes_30` bigint COMMENT '', 
    `file_open_num_lastscancycle_sum` bigint COMMENT '近扫描周期内文件累计打开次数', 
    `tbl_ref_num_lastscancycle_average` double COMMENT '近扫描周期内表平均引用JOB次数', 
    `tbl_visit_num_lastscancycle_sum` bigint COMMENT '近扫描周期内表累计被访问次数', 
    `file_open_num` bigint COMMENT '当天的文件打开次数', 
    `themedomainsw` string COMMENT '主题域（英文）', 
    `domainlevelsw` string COMMENT '表分层（英文）', 
    `tbl_write_num` bigint COMMENT '当天表write次数', 
    `tbl_write_num_all` bigint COMMENT '累计的表write次数', 
    `tbl_write_num_lastscancycle_sum` bigint COMMENT '最近一个扫描周期累计的表write次数', 
    `offline_level` bigint COMMENT '表推荐下线级别：0:不推荐 1:弱推荐 2:强推荐', 
    `hot_reserve` string COMMENT '数据温热保留时间', 
    `delete_dir` string COMMENT '数据处理策略', 
    `last_scan_cycle_new_storage_size` double COMMENT '最近一个扫描周期的表新增存储量', 
    `last_scan_cycle_new_file_num` bigint COMMENT '最近一个扫描周期的表新增文件数', 
    `tbl_last_scan_cycle_change_num` bigint COMMENT '最近一个扫描周期的表修改次数', 
    `reference_tbl_num` bigint COMMENT '被表引用次数', 
    `non_standard_path_num` bigint COMMENT '不规范路径的分区数量', 
    `has_lifecycle` string COMMENT '是否已设置生命周期', 
    `has_owner` string COMMENT '是否有负责人', 
    `warm_size_total_from_file` double COMMENT '温集群文件大小', 
    `par_num` bigint COMMENT '分区数量', 
    `little_file_count` bigint COMMENT '小文件数量', 
    `little_file_par_num` bigint COMMENT '小文件分区数量', 
    `offline_whitelist` string COMMENT '是否加入推荐下线白名单', 
    `lifecycle_whitelist` string COMMENT '是否加入生命周期永久保存', 
    `lifecycle_ticket_status` bigint COMMENT '生命周期永久保存审批状态，0：正常，1：审批中', 
    `offline_ticket_status` bigint COMMENT '下线白名单审批状态，0：正常，1：审批中', 
    `cold_reserve` string COMMENT '冷备保留天数', 
    `pg_id` bigint COMMENT '项目组id', 
    `file_merge_status` bigint COMMENT '小文件合并状态: 0：为开启，1：开启', 
    `implicit_type` string COMMENT '隐式类型，hiveOnKudu,hiveOnHbase,hiveOnArctic...', 
    `zorder_columns` string COMMENT '表z-order属性关联的字段', 
    `reserve_par_num` string COMMENT '生命周期保留分区数')
  ```

- 计算资源元数据
  ```sql
  CREATE TABLE `xx`.`dwd_meta_ calculate_detail_df`(
    `stat_date` string COMMENT 'stat_date', 
    `dw_ins_time` string COMMENT '数据插入时间', 
    `product` string COMMENT '来源：az/query/自行提交任务此字段有效；可选项有no_scheduler,azkaban,selfQuery', 
    `queue` string COMMENT '队列：az/query/自行提交任务此字段有效；若query为impala类型，此字段表示impala队列', 
    `task_name` string COMMENT '任务标识(具有全局唯一特性)名称：az/query/自行提交任务此字段有效；若是自行提交任务，则填充app_id\;若是query，则填充queryid', 
    `task_id` string COMMENT 'task_id:az/query任务有效，其中task存储az的projectid（非全局唯一）, query存储的是query_id', 
    `task_alias_name` string COMMENT '任务显示名称：az/query/自行提交任务此字段有效；若是自行提交任务，则填充app_id\;若是query，则填充queryname', 
    `task_type` string COMMENT '任务类型：az任务此字段有效；可选项为flowGroup,flow,job', 
    `flow_name` string COMMENT '流标识名称：az任务此字段有效', 
    `flow_alias_name` string COMMENT '流显示名称：az任务此字段有效', 
    `job_name` string COMMENT 'job名称', 
    `job_type` string COMMENT 'job类型', 
    `instance_id` string COMMENT '实例ID：az/query/自行提交实例此字段有效；若是自行提交任务，则填充appid', 
    `total_duration` double COMMENT '整体耗时：az/query此字段有效；单位为s\;计算方法为（结束执行时间-开始执行时间）', 
    `exec_duration` double COMMENT '执行耗时：az/query/自行提交任务此字段有效；单位为ms\;计算方法为所有appid最晚减去最早的时间；物理含义为yarn上等待和执行的时长', 
    `period` string COMMENT '调度周期：az此字段有效\;', 
    `schedule_exec_time` string COMMENT '计划执行时间：az任务此字段有效；节点的计划执行时间是继承流的计划执行时间', 
    `start_exec_time` string COMMENT '开始执行时间：az/query任务此字段有效；反映为az和mammut上的开始执行时间', 
    `end_exec_time` string COMMENT '结束执行时间：az/query任务此字段有效：反映为az和mammut上的结束执行时间', 
    `yarn_start_exec_time` string COMMENT 'yarn开始执行时间：az/query/自行提交任务此字段有效；计算方法为节点/query实例对应appid中最小的时间', 
    `yarn_end_exec_time` string COMMENT 'yarn结束执行时间：az/query/自行提交任务此字段有效；计算方法为节点/query实例对应appid中最大的时间', 
    `task_owner` string COMMENT '任务负责人：az任务此字段有效；az任务反映为此字段上流的负责人', 
    `yarn_app_num` bigint COMMENT 'yarn app个数：az/query/自行提交任务此字段有效；', 
    `submitter` string COMMENT '任务提交人：az/query/自行提交任务此字段有效；若为az，则为提交人；若为query，则为执行人；若为自行提交，则填入username字段（通常为产品账号或bdms_邮箱前缀）', 
    `releaser` string COMMENT '调度设置人：az任务此字段有效', 
    `cpu_cost` double COMMENT 'CPU消耗：az/query/自行提交任务此字段有效；单位为核*s；计算方法为所有appid对应的cpu消耗之和', 
    `memory_cost` double COMMENT '内存消耗：az/query/自行提交任务此字段有效；单位为MB*s；计算方法为所有appid对应的内存消耗之和', 
    `budget` double COMMENT '成本', 
    `source` string COMMENT '来源：azkaban/no_scheduler', 
    `exec_type` string COMMENT '执行方式', 
    `submitter_email` string COMMENT '任务提交人邮箱：az/query/自行提交任务此字段有效；若为az，则为提交人；若为query，则为执行人；若为自行提交，则填入username字段（通常为产品账号或bdms_邮箱前缀）', 
    `releaser_email` string COMMENT '调度设置人邮箱：az任务此字段有效', 
    `task_owner_email` string COMMENT '任务负责人邮箱：az任务此字段有效', 
    `task_info_fullname` string COMMENT '联合字段', 
    `update_time` string COMMENT '更新时间', 
    `create_time` string COMMENT '任务调度创建时间', 
    `job_state` string COMMENT 'job状态', 
    `spark_version` string COMMENT 'spark版本')
  ```

  

## 数据血缘

### 数据血缘功能

清晰知道表/任务上下游，方便排查问题，知道下游哪个模块（字段更变、表名更变等）在使用，提升开发效率及后期管理维护

### 数据血缘类型

- 活跃血缘：指离线开发线上调度产出的血缘，且调度持续生效
- 静默血缘：指离线开发中，开发模式运行、线上调度已运行过但是已取消调度、线上模式严重逾期执行等。静默血缘在图中用虚线连线表示

### 数据血缘项目中使用

- 数仓中表/字段上下游查询、发送字段变更通知、
- 探查除数仓外其他场景使用例如报表、olap库等等

### 如何开发血缘功能

- 团队合作搭建
- 使用现成组件/二次开发

### DWD元数据血缘表

```sql
CREATE TABLE `ehr`.`dwd_meta_table_lineage_detail_df`(
  `join_name` string COMMENT '关联用表名', 
  `table_layer` string COMMENT '表分层', 
  `relation_table_id` string COMMENT '血缘表id', 
  `relation_type` bigint COMMENT '血缘类型：-1-上游 1-下游', 
  `relation_cata_log` string COMMENT '血缘集群or数据源', 
  `relation_db_name` string COMMENT '血缘库名', 
  `relation_table_name` string COMMENT '血缘表名', 
  `relation_layer` string COMMENT '血缘分层', 
  `lineage_update_time` string COMMENT '血缘同步时间', 
  `relation_join_name` string COMMENT '血缘表关联用表名，库名.表名')
```

# 数据基建-数据指标体系

指标定义：指标是用来衡量、评估和描述数据的特征、性能或关系的度量标准,换句话说,指标是对不同维度(包括粒度)进行事务的描述,同时指标在生活中也与大家息息相关,就拿减肥这件事来说,粒度到用户,用户最近30天减肥斤数即指标,同时亦可通过指标来量化事实的好坏,来进行评判,例如某用户最近30天减肥斤数如果=0斤,平均线为5斤,即为指标不达标。

## 指标体系建设目的

与下游（风控/bi）达成合作，保障指标建设时口径的统一，完成指标覆盖，提升复用性，通过可视化方式提升查询效率

## 指标体系建设难点

- 能否与下游达成共识（沟通）
- 指标能否做到数仓收口：对外提供一个接口。多接口不好管理

- 需要与其他部门配合（数据平台/前端），进度难把控，容易烂尾
- 如何推广给下游
- 开发变更/下线规范难保障

## 指标标准

- 来源表信息保持一致：做到尽可能从“核心表”复用字段
- **口径统一（多数在dws层）**
  - 业务口径（偏文字描述）
  - 计算口径（sql代码）
  - 计算维度统一
- 指标类型
  - 原子指标：原子指标指的是基于业务过程的度量值，顾名思义是不可以在进行拆分的指标，如交易笔数、交易金额、交易用户数
  - 派生指标：基于原子指标、时间周期和维度，圈定业务统计范围并分析获取业务统计指标的数值，派生指标=原子指标+业务限定+统计周期+维度的组合（统计粒度），如交易金额的完成值、计划值，累计值等
  - 复合指标：指建立在基础指标之上，通过一定运算规则形成的计算指标集合，如平均用户交易额、资产负债率、同比、环比、占比等
- 指标更变/下线流程
  - 指标更变：    如果发现字段变更后对下游自己的表/报表产生影响，那自己负责修改代码并让其他同学进行代码审核、数据质量审核且任务运行成功后方可发布线上    如果下游血缘存在不是自己的表/报表，需要在相关业务群里说一下/找到下游表owner/报表owner发送通知，让下游owner进行修改，如联系不上需要向owner的leader说明问题，并且让下游表/报表的owner当天回复一下受不受影响，不回复则对方承担问题责任，如果对方不接受修改方案，需要双方约定一下修改内容、修改日期，重定方案
  - 指标下线：如果发现下游都是自己的表/报表，那自己负责将代码中的字段下线（字段下线不是删表从建，而是将字段置空等操作）并让其他同学进行代码审核，任务运行成功后方可发布,并且去除相应字段dqc检测（如果有该字段dqc的话）    如果下游血缘存在不是自己的的表/报表，需要在相关业务群里说一下/找到下游表owner/报表owner发送通知，让下游评估字段下线对下游的影响，如果评估没问题则让其进行代码中的字段下线，如联系不上需要向owner的leader说明问题，如果对方不接受字段下线，需要双方约定一下时间进行商讨

## 如何开发指标平台

略

## 如何与其他团队完成指标平台共建

（内部指标中心搭建，也可购买云端产品）略



# 数据质量

## 数据质量简介

- 概念：数据质量，意如其名，就是数据的准确性，他是数据仓库的基石，控制好数据质量，是做数据仓库基本要求，也使得下游业务方对数据用的放心

- 痛点
  - 数据问题该如何上报修复，缺少流程化
  - 数据链路缺少卡点保障
  - 数据不能及时产出影响到下游用数
  - 用户无感知，处理发现的问题数据，隐藏的数据问题仍存在

## 数据质量保障措施

数据质量保障措施-全流程卡点总览

<img src=".\image\数据质量_全链路保障.png" style="zoom:50%;" />

### 上线与更变规则

- 模型上线/更变流程：
  - 模型上线：设计模型-->组内模型评审-->代码编写-->提交运行(dev环境)-->代码审核数据校验(数据校验时需要给审核人提供数据比对结果)-->配置DQC-->数据初始化(线上环境)
  - 模型变更（例如加字段）：确定需求(了解需求背景)-->代码编写-->提交运行(dev环境)-->代码审核&数据校验(数据校验时需要给审核人提供数据比对结果)-->配置DQC（可省略，或添加业务dqc）-->数据初始化(线上环境)
- 指标更变：如果发现字段变更后对下游自己的表/报表产生影响，那自己负责修改代码并让其他同学进行代码审核、数据质量审核且任务运行成功后方可发布线上    如果下游血缘存在不是自己的表/报表，需要在相关业务群里说一下/找到下游表owner/报表owner发送通知，让下游owner进行修改，如联系不上需要向owner的leader说明问题，并且让下游表/报表的owner当天回复一下受不受影响，不回复则对方承担问题责任，如果对方不接受修改方案，需要双方约定一下修改内容、修改日期，重定方案

### 代码检验工具

略

### 数据上线前保障

- 数据探查：解决数据模型开发及添加字段后具体内容看不清晰的情况，如果没有平台工具可以通过手写sql去看分布。
- 数据比对：解决数据模型添加字段后是否会影响原有数据问题，如果没有平台工具可以通过dolphin scheduler（地址：dolphinscheduler.apache.org/zh-cn）去解决
- 指标如何验证逻辑正确？：可通过写ods层数据表关联后的查出来的一部分数据与自己开发指标的数据比对，前提是主键要唯一，这里可能有人问这里只能测出一部分问题数据，看不到隐藏问题？对于这种细节类数据问题是不可能照顾的到的，所以我们只需要保证模型&指标80%准确即可，完全没问题耗费人力投入不太值得，除非是真的没需求了。

### 数据质量监控（DQC）

dqc全称Data Quality Center，中文又称数据质量监控，用于监控表/字段数据的质量，防止问题数据流入下游任务，是数据仓库强有力的保障卡点，dqc触发于每个任务执行后

- 种类
  - 强规则：强规则可以中断任务的进行，将任务置于失败，并对任务负责人及值班人发送任务失败的消息（消息包括电话、邮件、短信、钉钉、飞书等）
  - 弱规则：弱规则不能中断任务的进行，只对任务负责人及值班人发送任务失败的消息（消息包括电话、邮件、短信、钉钉、飞书等）
- DQC划分
  - 基础DQC（每个表必加）
    - 主键唯一
    - 主键不为空
    - 表行数波动
    - 表不为空
  - 业务DQC
    - 文本类
    - 数值
    - 枚举值
    - 日期
- DQC处理：1.如果是由于轻微波动例如你定范围为0-20%结果21%可以置成功任务 2.如果你是大波动例如表行数为空，那就要看看上游任务产出情况，可能是没做好依赖，需要等上游跑完再重跑任务 如果是重要字段为空 或者主键不唯一要看看具体数据情况及时调整，例如group by去重或者临时填补

### 数据基线及SLA

- 数据基线概念（数仓内部）：数据基线是指数仓内部对数据产出严格把控标准，当数据产出较晚（可能任务报错、强dqc拦截等因素导致），会通知对应的值班人及任务负责人解决任务保障底层数据按时产出，在布置基线时会配置基线告警时间
- SLA概念（下游业务方）：sla是指数仓与业务方约定好的数据产出时间，像是与业务方“签字画押”，能够按时为下游提供数据，当数据产出较晚（可能任务报错、强dqc拦截等因素导致），会通知对应的值班人及任务负责人解决任务保障底层数据按时产出，在布置基线时会配置基线告警时间
- 基线SLA等级：例如L1-L4，等级越高（L4），基线分配资源越多
- 基线值班手册：由于夜间起床值班，值班人比较困倦大脑不够清醒，很容易做出有问题的操作，例如随意将任务置成功，针对这块问题需要组内制定值班手册来杜绝这类问题发生，让值班人一目了然

### 容灾备份快恢能力

- 背景：伴随着基线及SLA平台衍生出另一种容灾备份快恢能力，主要解决以下几类问题：核心任务产出不及时，以及值班同学及任务负责人夜间未起来，无法保障数据及时交付下游。

- 痛点：核心任务产出不及时，以及值班同学及任务负责人夜间未起来，无法保障数据及时交付下游。
- 解决办法：通常给下游临时任务切换为t-2数据（后面再补最新的数据），恢复整体任务进行，但数据资产、数据应用模型较多不能顾全还容易出现误操作情况，所以需要容灾备份任务还原所有数据资产，保障SLA补破线能够及时交付。

### 数据问题上报

- 痛点：下游缺少反馈数据问题渠道，也不清楚提出的问题是否解决，问题提出过于分散，需要平台管理整体流程
- 数据问题上报平台
  - 无平台的话：通过Wiki、飞书等管理数据上报问题，业务方通过工单方式上报问题到数据仓库同学，数据仓库同学跟进，并记录问题跟进情况，使得双方相互了解，从而完成数据问题统一管理，统一解决，注意：这里一定要用在线文档


### 数据质量长期监测跟踪体系(面向下游)

具体可见./数仓建设实践路线

- 痛点：数仓本身仍存在数据质量问题，解决了数据问题无法保障日后是否还出现此类数据问题产生，下游用户无法感知具体产生什么数据问题及问题具体明细
- 整体代码架构：
- 流程：
  - 1.现状梳理：对目前现有数据问题，存在隐患的问题进行收集归类，制作规则维表 
  - 2.规则构建：将目前存在的数据问题按照每个规则进行模块化规则配置，为每个规则配置规则内容，包括规则类型、规则id/名、以及存在问题的字段/表等 
  - 3.数据开发：建设相应dwd数据模型进行明细数据存放，并做维度退化，可按照规则种类开设二级业务域（模型为二级分区，分区1为ds（业务日期），分区2为rule（规则）），内容包括规则id规则名称，监控字段1-5，来源表，规则是否触发，规则是否加白，规则上线/变更/下线日期，规则状态，负责人等等 
  - 4.数据应用：将数据明细插入最终报表数据模型中，最后通过报表的数据汇总呈现
- 数据质量监测门户

## 如何推动上下游开展数据质量活动

- 初期：早期未做平台时候，可以通过组建数据问题答疑大群方式，与业务方进行沟通，明确业务方数据问题痛点，同时也能解决群里业务方提出的问题，其次与下游交流明确产出保障，打好基础
- 成熟期：当平台完善后，要经常开设培训讲座，带着下游了解数据质量体系，明白该如何按照流程进行数据问题上报，解决，验收，保障大家维护同一个规则，其次要适当给予下游奖励，例如每月一次统计数据问题提出贡献及数据问题解决个数、程度，并通过这些考核为下游提供奖励，让下游有了参与感

## 数据质量保障如何量化产出

- 产出统计数据模型
  - 问题发生数/率
  - 问题解决数/率
  - 问题复发数/率
- 周/月报告
  - 数据问题趋势
  - 数据问题分类
  - 本期解决数
  - 本期新增数
  - 重点问题解决数
  - 数据问题贡献榜
- ...

## 数据质量个人思考

全链路数据保障是整个数据仓库中的核心，好的数据质量基建要从需求分析->开发->提交/发布->应用，每一个流程都有相应的数据质量保障卡点，保障流程中每一步都不可缺失，如果大家都能遵守流程中每一步去执行，能降低线上问题产生频率，提升下游整体用数信心

- 初期：早期未做平台化，可以通过组建数据问题答疑群方式，与业务方进行沟通，明确业务方数据问题痛点，同时也能解决群里业务方提出的问题，其次与下游交流明确产出保障，打好基础。
- 成熟期：当数据平台功能完善后，经常开设培训讲座，带领下游熟悉数据质量体系，明白该如何按照流程进行数据问题上报、解决、验收，保障大家维护同一个规则；其次要适当给予下游奖励，例如每月一次统计数据问题提出贡献及数据问题解决个数、程度，并通过这些考核为下游业务方提供奖励，让下游业务方有参与感。

# 数据安全

## 数据安全实施难点

- 下游模型过多：迁移或修改时模型存在大量依赖关系，需要投入更多时间，存在修改时遗漏，修改错误导致线上问题发生
- 迁移周期：由于下游依赖了待修改模型，导致不能一次性做到模型完全迁移，需要排期按阶段迁
- 业务限制：各部门/业务对数据安全权限把控度不同

## 数据安全保障流程

### 数据安全保障大图

![](.\image\数据安全保障大图.png)

### 角色管理

对不同使用/开发角色提供不同使用权限

### 数据使用权限申请

- 权限审批
- 查询范围
  - 行权限
  - 列权限
  - 表权限
- 查询结果：原始数据(ODS)、明细数据(DWD)、指标数据(DWM、DWS)不对业务透出

### 数据表分级

- S1——非业务核心表：对公开数据，建议实施基本技术和管理措施
- S2——部门自建表：内部公开数据，其他部门使用数据建议实施必要技术和管理措施，可对外透露，需要走表/字段权限申请流程
- S3——部门自建表：敏感数据，其他部门使用存在较低的风险，建议实施较严格技术和管理措施，可以对外部分开放，例如部分字段申请、视图开放
- S4——业务核心表：机密数据，其他部门使用数据存在较大风险，建议实施严格技术和管理措施，通过加密方式提供其他部门

### 数据脱敏

根据查看表的人群、查看的内容（多数使用于门户、报表、对外透出表等场景）来脱敏，例如用户手机号，身份证等数据脱敏，脱敏可在ODS、也可在ADS做，看具体业务场景，例如橘厂在ODS完成脱敏操作

### 安全接口人卡点设定

- 数据使用申请时卡点负责人
- 角色组

### 数据传输

相关申请与查询操作需要通过专门的API接口进行，并且有高安全等级的加密措施

### 数据产生

通过数据分级体系对敏感表打标签(例如高风险预警标签)

### 数据展示

根据报表、看板的权限等级，在同一个图表中限制不同的用户能够看到的数据也不一样(常用于报表各模块内容展示)

### 数据销毁

敏感数据仅在hdfs上做逻辑删除是不够的，需要配合物理删除同步清理敏感数据

### 数据下载

数据下载需要设计多层级审批（可以直达业务负责人），限制下载行数（最多1000行）

### 风险管理

- 离职回收
- 超长时间未使用回收：定期（7/30/90天）扫描表使用情况，并通过公告、邮件等方式通知下游，对下游长期未使用回收
- 与其他部门共担风险记录：给予权限后，签字画押，可通过数据模型、平台化审计操作控制方式记录当前使用，对高风险操作监控,做到相互监督，并留下证据

## 数据安全实施阶段

### 早期

- 角色权限限制
- 数据使用申请限制
- 机密数据单独管控

### 成熟期

- 数据表划分管控
- 跨部权限使用限制
- 隐私数据处理
- 数据下载查询管控
- 敏感数据打标
- ...

### 无平台怎么做

- 角色权限管控
- 脱敏配置
- 数据表分级-元数据记录
- 数据操作流程，例如数据下载、需要上报（可以通过邮件等）
- 机密数据单独项目空间存放

## 数据安全如何量化产出

衡量指标：

- 数据安全分级未打标表数
- 永久权限/长期未使用表数
- 机密数据-对外透出表数
- 脱敏表/字段数

## 数据安全思考

数据是重要的资产，合理地使用能为企业带来巨大的价值，但同时数据安全管控不佳则会对企业造成更大的风险，数据泄露可能会造成业务失信于客户、导致经济损失等影响



# 数据治理

## 数据治理背景

- 概念：实际上数据治理的范畴相当广泛，按照Google对于数据治理的定义，它包含了数据生命周期（从获取、使用到处置）内对其进行管理的所有原则性方法。涵盖确保数据安全、私有、准确、可用和易用所执行的所有操作，包括必须采取的行动、必须遵循的流程以及在整个数据生命周期中为其提供支持的技术

- 本质：数据模型合规，部门及下游易用且有保障，提升开发及使用效率，发挥数据的价值，降本增效最大化数据使用的ROI，同时团队人员技术提升
- 要解决的问题
  - 合规
    - 元数据合规，各模型未按照数据标准规范制作
    - 数据安全合规，模型未做权限管控，被下游随意引用
    - 数据质量合规，数据质量问题发生频发、缺少链路保障
  - 资源
    - 存储，无用数据模型较多，存在不必要存储周期
    - 计算，无效任务、数据倾斜任务、高读写任务

## 业务发展阶段

- 探索期（定义框架）
  - 业务特点：单一、少量的业务模式探索
  - 数据诉求：快速支持业务团队包括数据分析、运营、风控等

- 扩张期（快速支持业务）
  - 业务特点：快速扩张
  - 数据诉求：数据的产品复用，数据全面精准

- 发展期（做数据服务、数据治理）
  - 业务特点：高增长、精细化运营
  - 数据诉求：数据指标一致性、产品多样易用

- 变革期（治理、数据安全进一步深化）
  - 业务特点：发现新机会、精细化运营
  - 数据诉求：快速支持业务创新，提高治理效率


## 数据治理内容

### 合规

详细见 .\数仓建设学习路线.xmind

#### 数据质量

- 思路：质量标准->强管控->定期扫描->体系化
- 规范化
  - 任务上线/变更流程
  - 指标变更流程
- 强监控
  - DQC
  - 数据基线及sla

- 定期扫描
- 体系化
  - 问题上报流程平台
  - 数据质量长期监控跟踪体系

#### 模型（元数据）

- 问题：由于早期业务快速扩张，对元数据把控不到位，导致成熟期出现大量不合规模型
- 思路：数据标准->建设管控->定期扫描
- 数据标准
  - 表/字段命名
  - 其他元数据补充（owner清晰、表中文名+使用说明、每个模型颗粒度、主键等）
- 建设管控
  - 模型评审：通过mentor、leader对模型补充以及建议提出优化模型内容
  - 代码上线强管控：代码提交强审核，保障内容修改无问题后上线
- 定期扫描：分层情况（保障模型引用合理）
- 烟囱模型及时下线
- 数据链路合理性：减少因内容不足产出烟囱模型或其他互补（指a表缺少指标与b表互补但属于同一个数据域）模型，从而导致相互依赖加长链路情况

#### 数据安全

见之前数据安全模块

### 资源

详细见 .\数仓建设学习路线.xmind

#### 存储

- 问题：业务发展中，存在大量无用待下线的数据表，及生命周期设定过长的数据表，未做整治
- 思路：盘点现状->建立优化方案->定期扫描成本归于个人及团队
- 盘点现状：梳理出长期未被使用/引用模型，及生命周期不符合当前标准模型，未分区，空表，文件数，文件格式等（通过数据血缘模型或平台捞出）
- 建立优化方案
  - 设置统一表生命周期，并对当前表按照新标准裁剪，对未分区表重制定分区
  - 长期未引用/被使用/临时的表下线
  - 压缩格式/存储格式优化
  - 根据业务对表存储重划分：对较大数据量表可以采取全量转增量操作、拉链表操作
- 定期扫描
  - 空表
  - 表存储格式为txt，建议使用orc或者parquet
  - 未设置生命周期
  - 表未分区
  - 生命周期未按标准裁剪

#### 计算

- 问题：业务成熟期，常会遇到，任务资源消耗大，运行时间过长，甚至存在未被引用模型对应任务空跑情况，导致计算资源浪费
- 思路：盘点现状->建立优化方案->定期扫描成本归于个人及团队
- 盘点现状：梳理出数据倾斜，消耗大，运行时间过长，空跑等任务（通过meta模型或平台捞出）
- 建立优化方案：
  - 空跑任务/未引用模型对应任务下线
  - **运行时长过长、资源消耗大任务找原因**：数据倾斜根本问题存在于key的分布不均，在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。（具体见八股）
    - 参数层面
    - map阶段层面
    - reduce层面
    - 其他层面：spark3 aqe：
      Aqe工作原理：当查询任务提交后，Spark就会根据Shuffle操作将任务划分为多个查询阶段。在执行过程中，上一个查询执行完之后，系统会将查询结果保存下来，这样下一个查询就可以基于上一个查询的结果继续进行计算了 SQL语句和数据分布对SQL进行解析、优化和执行的，但由于执行计划是预估的，准确性很难保证，因此执行计划并不是最理想的。有了AQE后，Spark就可以在任务运行过程中实时统计任务的执行情况，并通过自适应计划将统计结果反馈给优化器，从而对任务再次进行优化，这种边执行、边优化的方式极大提高了SQL的执行效率。 Spark3对小文件自动合并
  - 针对任务调度时间规划不合理，导致部分时间段资源消耗较高任务，提前/延后任务调度时间，做到资源合理分配利用
  - 对于数据价值较低/烟囱开发/无效监控项任务，需要及时下线或将字段迁移至核心表
  - 规划核心任务 并分配任务执行优先级 把非核心的任务靠后运行
  - 采用z-order+spark排序算法提升join等读取效果
- 定期扫描
  - 超长任务：任务实例的运行时长大于5小时	
  - 无效计算：产出的表为当前项目中推荐下线表
  - 高消耗任务：资源消耗连续7天拍入前10


#### 其他

- 小文件处理
  - 小文件是如何产生的：
    - 1.动态分区插入数据（使用的spark2 mr引擎），产生大量的小文件，从而导致map数量剧增 
    - 2.reduce数量越多，小文件也越多(reduce的个数和输出文件是对应的) 
    - 3.数据源本身就包含大量的小文件
  - 小文件问题的影响：
    - 1.从Hive的角度看，小文件会开很多map，一个map开一个JVM去执行，所以这些任务的初始化，启动，执行会浪费大量的资源，严重影响性能 
    - 2.在HDFS中，每个小文件对象约占150byte，如果小文件过多会占用大量内存。这样NameNode内存容量严重制约了集群的扩展
  - 小文件问题的解决方案：
    - 1.使用spark3，能够自动合并小文件 
    - 2.减少reduce的数量(可以使用参数进行控制) 
    - 3.用distribute by rand控制分区中数据量

### 数据价值

详细见 .\数仓建设学习路线.xmind

- 解决痛点：修复/下线数据价值不高模型，提升模型复用性及利用率
- 建立优化方案
  - 烟囱数据模型及对应任务、模型粒度重复及时下线
  - ads指标下沉到dws
  - 建立模型价值度指标，持续下线低价值模型
  - 下线ads层对应业务不再使用的场景模型

### 人员成本治理

详细见 .\数仓建设学习路线.xmind

### 总结

- 模型合规（包括了元数据治理，原来只到了元数据层次）：1.数据标准重制定及修复，包括对原来数据域重构，表字段命名体系重构，并对原来模型按照新标准合规改造  2.元数据补充 owner、使用说明、字段中文名具体内容、颗粒度声明、主键声明等补充保障下游及内部使用时候清晰 3.制度建设：完善模型评审制度、代码提交强审核，保障内容合规后上线 4.分层合理性，治理不规范的模型分层引用，例如ADS层表依赖了非DWS层的表，建议优化   5.数据链路合理性（本次新补充内容）：减少因内容不足产出烟囱模型，从而相互依赖加长链路情况 

- 数据质量合规：1.流程化，任务上线/变更流程，指标变更流程 2.dqc管控：对原4大基础dqc进行补充以及核心业务模型dqc补充，并对原无效dqc下线，对常触发dqc进行调整（例如表行数波动，可通过算法对近7天数据量监测） 3.sla及基线治理（这里也可以放到人员运维roi治理中）：上线前把控，保障基线正常运行，核心任务优先产出且分配高资源，培训及整理值班运维手册，建设容灾备份快恢能力临时修复数据 4.上游问题数据治理：数据质量长期监测体系（详情见课程3-数据质量课件） 
- 数据安全合规：1.角色权限管控，对不同使用/开发角色提供不同使用权限，根据报表、看板的权限等级，在同一个图表中限制不同的用户能够看到的数据也不一样(常用于报表各模块内容展示) 2.数据脱敏，通过脱敏防止数据泄漏 3.表/字段分级：对每个表及字段进行打标，保障每张表都有数据安全管控 4.数据权限使用 表/字段走审批流程 并设置数据使用申请时卡点负责人/组  5.其他 数据下载管控（一般来说最多下载1000行/次），离职数据风险管控等等 
- 存储资源治理：1.设置统一表生命周期，并对当前表按照新标准裁剪，对未分区表重制定分区 2.长期未引用/被使用/临时的表下线 3.压缩格式/存储格式优化 4.根据业务对表存储重划分：对较大数据量表可以采取全量转增量操作、拉链表操作 计算资源治理：1.数据倾斜任务治理（后面我会细讲治理方法 这里跳过）2.消耗大core/内存任务治理 3.无效监控项、重复开发情况占用计算资源、数据价值低的模型占用计算资源及时下线 4.梳理数据链路并对任务调度治理 5.规划核心任务 并分配任务执行优先级 把非核心的任务靠后运行 6.小文件治理 7.其他 例如hive spark2 切换spark3采用aqe特性  采用z-order+spark排序算法解决join时读取效果提升 
- 数据价值治理 （整体来说是提升模型复用性）：1.烟囱数据模型及对应任务、模型粒度重复及时下线 2.ads指标下沉到dws  3.建立模型价值度指标，持续下线低价值模型 4.下线ads层对应业务不再使用的场景模型 
- 人力成本治理（这个可以不说）：1.指导培训组员技术侧/业务侧能力能够独挡一面，并完善文档沉淀帮助后续新人培训开展 2.让熟悉不同数据域的组员安排在合理的数据域范围，同时做backup 3.建立相应需求开发流程机制，统计人员产出效率，方便针对性安排后续开发内容4.为当前需求及项目难度打分，帮助大家更好意识到项目能否落地、以及产出时间，同时衡量每人产出roi

## 数据治理如何量化产出

指标化——产品化

- 背景
  - 难以量化
  - 积极性提升
  - okr对齐
- 日/周，治理推送
- 周报、月报
- 邮件推送
- 产品思路
  - 指标—— >钱
  - 团队治理技术能力提升
- 产品设计
  - 成本
    - 存储
    - 计算
  - 质量
    - DQC
    - 基线SLA
  - 模型
    - 规范度
    - 各个层级查询次热力图
    - 各个层级使用次热力图
    - 各个层级转化率漏斗图
    - 高热度模型使用总次数测试趋势图

## 数据治理推动

我们从3个点出发，

1.让下游配合最重要的是调动积极性，让下游感觉到治理能对他们起作用 或者说能让业务方也能做大蛋糕，因为数据治理对于下游来说可有可无 没你数据治理 下游数据模型不也跑的没问题嘛，所以就如花姐刚才说的该警告的警告 该配合的配合，但这个警告也只是表面你可以从费用分摊上去说，也可以从下游痛点去说，共同做好保障措施，让他们也能分到项目大家一起分蛋糕（下游肯定有需要治理的点，其中最痛的是数据质量），

2.除了这些还可以加一些奖惩措施比如我之前说的解决dq吃dq的活动，让下游觉得配合是有价值的，

3.还可以做到更大的推进作用，比如我们在和bi一起做治理等起了一定规模后可以发治理效果月报/周报 发送全部门，让其他部门也有感知

## 思考与沉淀

<img src=".\image\数据治理_思考与沉淀.png" style="zoom:50%;" />

对于数据治理每人都有自己的见解都有自己的方法及业内dama数据治理体系等，早期业务发展时，大家可以靠着流程，人为，标准等评估，随着业务发展成熟，靠着上述这些理论远远不足以支撑治理量，需要更多工具、平台接入，加速治理整治节奏，从而使人力投入更少，治理内容更多效果。

# 实时技术

## 架构及组件

- 架构
  - 流批一体架构
  - lambda框架
- 组件
  - 计算引擎：Flink
  - 中间件：Kafka
  - Olap：Doris

## 实时开发流程

### 接入数据

用flink CDC等，传到中间件中。即接数据源，到中间件中，形成流表

### 模型开发

- 内容：通过实时平台及计算引擎对ODS数据进行Join、清洗、转换、过滤、聚合、维度退化等（模型规范依旧采用之前建设思想） 完成DWD、DWS、ADS流表模型设计（部分公司这里不做dws，可能涉及原因链路过长影响实时进展），最后进行数据初始化
- 整体设计原则 
  - （1） 高内聚，低耦合 主要从数据业务特性和访问特性两个角度来考虑：将业务相近或者相关的数据、粒度相同数据设计为一个逻辑或者物理模型；将高概率同时访问的数据放一起，将低概率同时访问的数据分开存储。 
  - （2） 一致性 1.流/表命名规范需清晰、一致，流/表名需易于下游理解和使用。 2.字段释义注释、核心逻辑注释、代码整体功能注释规范。 3.相同的字段在不同表字段名相同，可参考《OneData规范化数据定义》说明。 
  - （3）易用性 底层公用的处理逻辑应该放在实时公共流进行封装与实现，不要让公共的处理逻辑暴露给应用层实现，不要让公共逻辑在多处同时存在，尽量通过标签化处理。 
  - （4） 时效性与易用性平衡 适当的数据冗余换取下游查询性能，不宜过度冗余与数据复制，结合实时指标处理性能和实际应用场景进行权衡。
- 任务测试

### 数据校验

其实应该包含在模型开发当中。

- 根本是解决实时离线数据无法保持一致 

- 1统一指标口径，同时复用指标中心逻辑 2保障数据来源一致 3拉消费点位跟离线比对

### 数据落地

将ADS表数据落地OLAP(Doris、Clickhouse等),加速查询，方便下游使用 

### 可视化

对Ads数据展示

### 实时监控

- 延迟警告
- 任务失败告警
- 主键冲突告警
- 数据波动告警

## 实时项目

- 项目名称：xxx活动可视化实时链路建设

- 项目背景：随着xxx业务发展迅速，对数据实效性要求提升，xxx数据组采用数据可视化、战报等方式支持xxx临近活动，助力业务更快捷获取数据信息
- 项目实现
  - 参考“模型开发”
  - 补充——压测，需要关注的核心指标，Failover，延迟，RPS
- 项目存在的问题、难点
  - 活动当天数据积压
  - 缺少实时链路兜底方案
- 问题思考
  - 数据挤压：提前做好压测，调整好任务资源（slots、TM内存、JM内存、并发数），利用好flink反压机制，如消费能力不足可以增加分区数同时提升消费组消费者数量，必要时准备实时双链路保障1条链路出问题时，另外一条能够立刻切换
  - 兜底方案：大屏多链路，准备多块不同链路的备屏（保障内容要与主屏不差）能够在主屏挂了后立刻无缝隙切换，其次要准备好数据，当所有大屏都挂了后将上次同样活动数据及时灌入，并在切换后能够及时修复主链路，不被业务方看出问题

## 实时链路优化

- 目的：让任务在目标峰值RPS（**系统在单位时间内能够处理的最大请求数量**）下，无延迟，且集群资源利用率在合理范围内
- 优化思路：
  <img src=".\image\实时链路优化思路.png" style="zoom:50%;" />
- 并发调优
  - 通过 web界面。可以发现，第13节点输入队列满了，进而反压到上面的节点，此时我们再点击下12节点->BackPressure->查看status，发现为high则确定性能瓶颈为节点13->调整节点13的并发度
- 内存调优
  - 选择瓶颈节点->查看OlD区内存是否频繁做FullGC
- 维表关联调优
  Async+partitionjoin+缓存 原始的维表 JOIN 是同步访问的方式，来一条数据，去数据库查询一次，等待返回后输出关联结果。可以发现网络等待时间极大地阻碍了吞吐和延迟。为了解决同步访问的问题，异步模式可以并发地处理多个请求和回复，从而连续的请求之间不需要阻塞等待。 目前 HBase 提供三种缓存策略，分别是 None， LRU， ALL。 None: 无缓存 LRU: 最近使用策略缓存，需要配置相关参数：缓存大小（cacheSize）和 缓存超时时间（cacheTTLMs） ALL: 全量缓存策略。即在 Job 运行前会将远程表中所有数据 load 到内存中，之后所有的维表查询都会走 cache，cache 命中不到则不存在，并在缓存过期后重新加载一遍全量缓存。
- sql调优：参考第七讲数据治理
- 其他
  - 算子链路优化
  - checkpoint间隔合理

## 实时技术如何量化产出

- xxxx大促实时大屏开发 or 改造
- 治理-监控保障体系迭代优化：由于近期新增较多无效报警，所以对监控指标、内容优化
- 治理-资源消耗
- 实时模型开发/治理
- 实时战报
- 实时风控

# 数据资产

## 目的

数据资产是对业务数据建设与沉淀， 其中最重要的核心是数据化运营与场景化分析，通过对用户基础信息、⾏为信息等模块进行打标，完成数据模型建设，来支持下游业务各个应用场景，达到易用、易管理效果。

## 数据资产建设内容

### 风控名单资产（金融业务项目）

**明白背景——>现状梳理（总线矩阵，确认ads内容，包括指标、标签等，这里是规则）——>数据模型的开发——>数据汇总（ID mapping和数据关联扩散）——>分控画像建设——>完善各类管理机制，资产门户机制**

注：ID mapping就是将多个ID，通过某种算法，转化为唯一的ID

#### 背景

我们是数据中台同学

- 对接业务方——风控中台——风控策略人员（偏运营）

- 业务痛点（风控中台）
  - 内部/外部 ——分散
  - 不够清晰
    - 是否核心
    - 常用
    - 新旧切换
  - 使用成本高——需要咨询技术同学
  - 无人维护
  - 新人入职——难懂
- 数据中台
  - 解决业务方的数据痛点
  - 建设管理体系

#### 构建过程

数据资产主要是面向ads的，要与业务沟通好指标。但ads需要dwd（数据基建）。所以在构建dwd时，也需要现状梳理，明确基础指标（原子指标、简单的衍生指标）

##### 现状梳理（总线矩阵）

- 根据主题域（数据域）和已有数据（内外部数据）对风控策略进行梳理
- 梳理现有的表

##### 规则制定(与业务沟通)

规则大类-规则二类-规则三类（实际就是每一个标签）

比如：金融负面（大类）- 贷款逾期 - 逾期30天以上

##### 数据开发

需要考虑数仓建设五要素（数据域、事实、维度、颗粒度、度量）

- 架构

  - 串行：产出时间晚
  - 并行：资源消耗大

- 模型建设：

  dwd也可以
  数据源来源于多方，比如内部信贷系统，外部人行 蚂蚁数据，公安 司法数据等，这些分散的数据都是ods ，我们按照金融负面 公开负面给他区分成数据域，那这里就会按照数据域形成多个dwd 数据表，每个规则也都是按照域在这个dwd 数据中存放，同时这里关联dim rule这个维度表，这个维度表是手工维护的维度表，也就是说跟业务确认后去维护的，他有规则信息，然后把规则信息维度退化到刚才说的dwd 明细中存放

- 颗粒度

- 维度

  - 场景
  - 规则

- 分区

  - 业务日期
  - 规则id

- 脱敏

  - md5
  - 模糊

- 数据质量

  - 数据加白
  - 数据清洗

- 数据类型

  - 行存储
  - json
  - 复杂类型

 ##### 关系扩散

- 关联关系算法模型（算法开发）
- 扩散类型
  - 法人信息与企业
  - 手机号扩散
  - 紧急联系人扩散
  - id扩散

##### 风控名单建设 

- 规则组合 —— 圈选人群（ads层）
- 为业务方提供数据——策略操作
  - 黑名单
  - 策略
  - 用户风险画像

#### 管理维护

- 规则上线维护机制
- 规则变更维护机制
- 模型建设管理
- 负面信息资产门户
  - 规则id
  - 规则名称
  - 规则负责人
  - 规则上线时间

#### 模型构建大图

<img src=".\image\数仓建设学习路线_风控名单资产模型建设大图.png" style="zoom:50%;" />



#### 量化产出

- 模型建设
  - 公开负面、金融负面、经营负面等X类二级风控负面数据域建设
  - 内容包括XXX条负面规则
  - 拦截XXXX万量级风险名单
  - 通过XXX条负面规则组合，完成XXX个场景下风控策略画像定制

- 管理机制
  - 业务层面
    - 场景接口人管理
    - 规则纳入推出机制
  - 技术层面
    - 权限收口
    - 数据质量

#### 项目难点

原有负面信息凌乱、底层逻辑繁杂，涉及 XXX张底表、未对负面信息进行主题分类，且部分外部数据未清洗，从而在模型设计时存在逻辑无法拉齐、外部数据解析较为麻烦、规则难以归类等痛点。

### 用户画像标签资产（b2b金融项目）

#### 背景

随着业务快速发展，与之相伴随的是核心能力的建设与沉淀， 在核⼼能⼒中，数据化运营能力 与场景化分析能⼒离不开强大的数据基建支持，而场景用户资产的建设、用户的刻画与分层又是数据基建的重中之重。当前数据分析团队、数据开发团队及各相关技术团队正在联合搭建数据化运营能力， 本项目以解决内容侧的用户标签缺失问题为目标，以场景中用户资产为建设对象，重点加工数据化分析过程中常涉及的 基础信息、行为信息等模块，并打通标签生产与应用服务链路，支持xxx应用场景

- 对接业务方：数据分析
- 业务痛点
  - 标签缺失：未做用户标签沉淀，无法支撑用户群体及画像分析
  - 场景化
    - 多场景下数据/标签分散
    - 未做场景化标签资产划分
  - 未做资产沉淀（各个指标分散在不同的表）：后期引用/取数代价较大
  - 标签口径规范缺少统一
- 数据中台
  - 解决业务方场景化标签/画像制定
  - 做到标签统一收口（标签统一管理）
  - 数据资产门户-标签资产可视化展示

 #### 构建过程

##### 现状梳理

- 业务场景（划分数据域）
- 用户标签内容（与业务方沟通），想要的指标
  - 标签类型
    - 枚举型
    - 指标
      - 复合指标是聚合来的
      - 派生由复合指标进一步加工（比如同比、环比）
    - 日期型：最后一次XXX的时间
    - ......
  - 内部自发补充标签——从原来dws、dwd表中将指标、文本内容沉淀
  - 业务方提供标签需求——与业务方讨论得出标签加工口径 
- 有哪些表
  - 驱动表——dim表（用户维表）——用户（买家/卖家）基础信息
  - 业务数据表
    - ods
    - dwd
    - dws

##### 模型开发

（模型建设五要素）数仓建设五要素（数据域、事实、维度、度量、颗粒度）

- 模型建设：选用驱动表（dim用户表，也可以是dwm）作为主表left join业务数据表将其字段放入模型当中
  - ADS层驱动表可以是dim也可以是dwm
- 业务场景——按照不同金融产品进行不同颗粒度划分
- 模型命名：ads\_一级主题域\_二级主题域\_颗粒度\_业务过程
- 颗粒度
- 维度
- 分区——业务日期
- 标签内容——标签梳理，参考现状梳理

##### 画像建设

- 对标签进行分组：一级分组如:基础 信息、平台经营、金融行为等;二级 分组如 :店铺 信息、 交易信息、 申请开 通、还款信息 等。
- 标签组合/平台操作：圈选人群（ads层模型）-圈选客群
  - 根据一个或多个指标合起来，打一个标签。多个标签构成一个画像


#### 管理维护

- 标签上线维护机制（需求平台）：找到收口人、卡口人（层层审批）
- 标签更变维护机制
- 氮气无用标签扫描下架
- 画像标签数据资产门户：按按需要打标的粒度（商品、商家、买家）。分类管理标签
  - 和指标中心很像
  - 让下游知道口径之类的，指标相关的基础信息


#### 量化产出

- 0-1 制作 x 种不同画像资产模型，建设xxx+个数据化用户标签，使的模型在后续使用更贴合不同场景业务，助力业务快速迭代发展

- 通过不同场景下标签完成场景画像制作， 总计xxx。

#### 项目难点

需要覆盖当前 xx种场景下买卖家标签，标签又存在多种类型制作量庞大，且需要对接各场景运营同学，拉齐需求分析，从而沟通成本也较大 

# 数据服务

## 数据服务要解决的内容

- 将数据通过平台/接口方式为下游数据分析/操作提供对应的服务，解决下游用数难，找数难的痛点
- 下游痛点
  - 指标/标签口径无法统一
  - 指标/标签口径无法通过平台化去查询
  - 想要的数据表无从找寻
  - 数据准确性存在问题
  - 报表卡顿、展示较慢
  - 需求维护提出无维护平台
  - 用户画像没办法自助分析（这里指有用户表标签，业务方没办法自助通过标签去分析）
  - 报表/实时大屏展示（不同公司细分领域不同，存在部分数仓干了bi的活）

## 数据服务内容

- 指标平台
- 标签/画像管理平台
- 数据地图/资产门户
- 数据问题上报及长期检验平台
- 数据输出收口
  - 解决形成统一数据接口（one service），向下游提供数据支持，并帮助下游报表/看板/产品等进行数据加速
  - api
  - olap
  - 数据库
  - 中间件
- 可视展示
- one_id
  - 解决id多样化、随着业务分散化无法统一使用及查询的问题
  - 通过表关联id扩散、算法同学提供id扩散表等方式、亦或者三方渠道购买数据方式将id整合一起，通过统一user_id查询出对应数据

## 数据服务建设周期

- 业务探索期——数据地图
- 业务扩张期
  - 可视化展示
  - 数据输出收口
  - one_id
- 业务发展期
  - 数据问题上报及长期检测平台
  - 数据资产门户
  - 标签/画像管理平台
  - 指标平台
- 业务变革期，内部开发工具，治理数仓，提升数仓开发整体效率
  - 数据治理平台
  - 效能小工具



# 数据应用

## 什么是数据应用

- 前言：数据如同石油等能源一样，如果只是接入平常使用而不提炼（例如石油能够提炼煤油）则会失去大量价值，在数仓建设中最核心部分则是将数据加工计算，通过多维度、多场景专项分析得到有价值的信息
- 通过对数据深度加工，通过部分指标计算及组合或者标签对特定情景进行模型建设，为下游报表、看板、ppt、产品、ab实验、风险拦截提供数据支撑，甚至可通过专项分析结果为算法提供数据，对情景进行预测 

## 数据应用项目（人力资源-员工离职动因专项分析）

见.\数仓建设学习路线.xmind



## 0-1如何搭建数仓？

- 选技术栈
  - 平台
  - 自建：自己串组件
- 定规范（做数据标准）
  - 代码开发规范
  - 模型规范
  - 命名规范
  - 上线规范
- 构建大图
  - 架构图：弄明白数仓各层都要去做哪些内容，每一层如何开发模型，如何评价模型。把这个流程写清楚
  - 数仓版图：见数仓建设内容大图及简介。（梳理上下游，数据从哪儿来）
    - 数据应用
    - 数据服务
    - 数据资产
    - 数据基建
  - 对业务的理解：把业务SOP（业务标准流程）全部画出来：
    <img src=".\image\客服域建设流程.png" style="zoom:50%;" />

​	

-  接数据：不一定要全部接，主要接核心数据
  - 离线数据的数据集成。
-  模型建设：根据模型规范建设模型
-  做链路保障
  -  代码上线流程
  -  数据基线，SLA
  -  配置DQC
  -  数据探查

-  数据支撑
  -  支持专项应用，保障看板等



# 数仓评价

从成本、数据质量、效率、数据安全、支撑等等这一块，从业务角度、技术角度，综合分析。

数仓评价好坏是对数仓全流程机制是否健全的评价，从技术方面，数据仓库应该具有成本、质量、效率要求，安全方向方面的能力，从业务方面，数据仓库应该支撑业务建设，覆盖尽可能多的业务场景，需要数据时能够及时取到，能满足业务数据化需求

## 数据质量

### 产生原因

- 技术
  - 缺少流程制定
  - 数据模型设计存在问题
  - 数据源本身存在问题
  - 数据清洗加工疏忽
- 业务
  - 业务理解不到位
  - 业务流程变更
  - 数据输入不规范
  - 业务系统烟囱林立
- 管理
  - 人才缺乏
  - 流程管理不完善
  - 奖惩机制不明确

### 评估方法

- 准确性：描述数据和客观实体特征是否相一致——通过DQC实现
  - 是否基础dqc覆盖全链路
  - 核心表业务dqc是否配置
  - dqc历史趋势
- 及时性：描述从业务数据能够被使用的及时程度
  - 是否有基线/sla（核心与较核心业务）配置
  - 基线/sla破线次数
  - 未按时交付数据次数（被业务方发现投诉）
  - 基线sla覆盖度
  - 是否具备快恢能力（当数据未产出时候，迅速定位还原）
- 一致性：描述同一个信息主体在不同数据集中的数据是否相同
  - 数据收口：核心指标沉淀到核心聚合模型，统一收口
  - 指标中心建设：保障指标统一：指标录入、指标复用、指标展示、指标口径查询有处可循
- 流程完整性
  - 数据质量长期跟踪监测体系
    - 收集问题
    - 解决/防止复发问题
  - 数据质量问题报告
    - 数据问题趋势
    - 数据问题分类
    - 本期解决问题
    - 本期新增数
    - 重点问题解决数
    - 数据问题贡献榜
  - 流程制定
    - 任务上线流程
    - 指标变更/下线流程

### 流程

- 事前，预防
  - 制定质量管理机制，开发/变更/上线流程
  - 工具/代码监控
  - dqc全链路基础配置
  - 核心数据稳定产出
  - 培训值班内容/明确数据问题如何定位
- 事后，复盘完善
  - 归因->解决方案->方法论、流程
  - 完善dqc规则
  - 问题上报监测
  - 保障数据统一收口，指标统一口径维护标准
  - 完善数据问题定位步骤

## 模型建设

### 产生问题的原因

- 技术
  - 无数据标准制定
  - 缺乏模型建设复用/拓展想法
- 业务
  - 对业务流程，环节理解不够
- 元数据管理
  - 团队模型艰涩和知道不足
  - 无模型评审机制

### 评估方法

- 规范度
  - 是否制定命名规范
  - 是否具有建设规范
    - 模型五要素
    - 模型分层具体操作内容
  - 是否有模型评审流程
  - 主题域归属
- 完善度
  - 元数据补充：owner清洗，表中文名等
- 复用度：模型被下游引用程度，是否是无效模型
- 稳定性
  - 运行时长
  - 是否数据倾斜
  - 对产出的影响
- 拓展性
  - 模型内容划分合理性（基础字段，指标），冗余低
  - 新增模型与老模型是否出现冲突
- 合理性：分层情况（保障模型引用合理）——跨层引用率——ods穿透率

### 流程

- 事前，预防
  - 制定模型开发规范（开发思路，模型合规）
  - 制定数据标准（命名、内容、代码等）
  - 培训指导模型建设开设模型评审会
  - 梳理业务流程
- 事后，复盘完善
  - 完善数据标准
  - 加强模型建设意识
  - 模型评分打分

## 数据安全

### 产生原因

- 技术
  - 数据安全意识薄弱
  - 未设立安全管控
- 业务
  - 各部门/业务对数据安全权限把控度不同
- 管理：未做风险管理
  - 离职回收
  - 有共担记录

### 评估方法

- 角色权限是否划分
- 权限管理制定
  - 下载权限
  - 数据使用权限申请
  - 数据使用申请时卡点负责人/组
  - 闲置的权限是否定期回收
- 数据表是否分级
- 对外数据是否脱敏
- 可视化展示是否分级展示内容

### 流程

- 事前，预防
  - 角色权限分级
  - 数据表权限管控（表/字段）
  - 核心/对外数据脱敏
  - 可展示内容把控
  - 全数据表分级
- 事后，复盘完善
  - 补充隐藏数据风险
  - 制定跨bu/业务数据把控范围
  - 定期对安全权限扫描

## 成本/性能

### 产生原因

- 技术
  - 运行时间过长
  - 运行报错
  - 重复建设
  - 数据倾斜
  - 数据价值与资源消耗不匹配
- 管理
  - 资源成本急剧上升
  - 维护成本越来越大
  - 数据之间的关系变得复杂
  - 数据模型的复用性低，烟囱建设

### 评估方法

- 无用/无效表是否及时下线
  - 无下游任务的表
  - 无上游任务的表
  - x天未被访问的表
- 表生命周期是否合理
- 数据倾斜任务数
- 运行超过xxxxh任务数
- 是否存在空跑任务
- 小文件过多数据表
- 是否有数据成本的量化管理

### 流程

- 事前，预防
  - 代码审核，检查代码是否需要优化
  - 试用完对临时表，无用表及时下线
  - 任务试验跑检查运行时间
  - 前置小文件合并操作
- 事后，复盘完善
  - 定期扫描无效表
  - 定期下线空跑任务
  - 数据治理前任务/表量化
  - 定期扫描模型生命周期
  - 每日/周推送top榜（消耗、资源存储top榜）

## 用户用数体验

### 产生原因

- 业务
  - 找数难
  - 用数难
  - 查询难
  - 自助分析难
  - 无法统一内容

### 评估方法

- 数据服务
  - 是否具备资产门户方便下游找寻业务表
  - 是否整合one id/one service完成数据输出统一收口
  - 是否具备策略/指标平台，方便下游了解，保障口径统一
  - 是否具备标签/画像/指标分析工具，使得下游自助查询，解放数仓资源

### 流程

- 事前，了解
  - 了解下游对数据使用习惯
  - 了解各业务方缺少那些应用缺陷
- 事后，完善数据服务内容
  - 补充数据平台建设

## 数据资产覆盖

### 产生原因

- 业务
  - 数据资产无法满足下游应用场景
  - 指标分散

### 评估方法

- 数据资产支撑
  - 是否完善用户画像/用户360资产
  - 各场景数据资产是否能全面支持
  - 零散指标/标签是否有专题整合

### 流程

- 事前，预防
  - 前置完成用户画像等常用场景数据资产沉淀
- 事后，完善数据服务内容
  - 完善全业务场景数据资产补充
  - 补充专项应用数据标签/指标模型













 
